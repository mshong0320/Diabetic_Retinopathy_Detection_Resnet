{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import csv\n",
    "import time\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from IPython import display\n",
    "from googleapiclient.discovery import build\n",
    "from skimage import io, transform\n",
    "import os\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.image as mpimg\n",
    "import scipy\n",
    "from scipy import ndimage, misc\n",
    "from scipy.misc import imshow\n",
    "import skimage\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import shutil\n",
    "import pdb\n",
    "import cv2\n",
    "\n",
    "plt.ion()\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"Using CUDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlabels = pd.read_csv(\"/home/jupyter/kaggle_data/trainLabels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 11 17:10:39 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 410.72       Driver Version: 410.72       CUDA Version: 10.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   54C    P0    59W / 149W |    934MiB / 11441MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      4358      C   /opt/anaconda3/bin/python                    923MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlabels.loc[:10,[\"image\", \"level\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of classes on kaggle training dataset\n",
    "trainlabels[\"level\"].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlabels.groupby(['level']).groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlabels.groupby(['level']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(trainlabels['level'].unique())\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/jupyter/kaggle_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This script is to divide the training dataset into categorical directories\n",
    "dataset = open('/home/jupyter/kaggle_data/trainLabels.csv', newline='')\n",
    "datalist = csv.reader(dataset)\n",
    "data = list(datalist)\n",
    "lines = len(data)\n",
    "i = 0\n",
    "\n",
    "for row in data:\n",
    "    image = row[0]+'.jpeg'\n",
    "    state = row[1]\n",
    "    print('({}/{}) Processing Image ({}): {}'.format(i + 1, lines, state, image))\n",
    "    i += 1\n",
    "    \n",
    "    if state is '0':\n",
    "        try:\n",
    "            os.rename(image, '/home/jupyter/kaggle_data/train/Normal/' + image)\n",
    "            print(' -> Moved to Normal')\n",
    "        except FileNotFoundError:\n",
    "            print(' -> Failed to find file')\n",
    "    elif state in ['1','2','3','4']:\n",
    "        if state is '1':\n",
    "            try: \n",
    "                os.rename(image, '/home/jupyter/kaggle_data/train/Mild_NPDR/'+image)\n",
    "                print(' -> Moved to Mild_NPDR')\n",
    "            except FileNotFoundError:\n",
    "                print('-> Failed to find file')\n",
    "        elif state is '2':\n",
    "            try:\n",
    "                os.rename(image, '/home/jupyter/kaggle_data/train/Moderate_NPDR/'+image)\n",
    "                print(' -> Moved to Moderate_NPDR')\n",
    "            except FileNotFoundError:\n",
    "                print('-> Failed to find file')\n",
    "        elif state is '3':\n",
    "            try:\n",
    "                os.rename(image, '/home/jupyter/kaggle_data/train/Severe_NPDR/'+image)\n",
    "                print(' -> Moved to Severe_NPDR')\n",
    "            except FileNotFoundError:\n",
    "                print('-> Failed to find file')\n",
    "        elif state is '4':\n",
    "            try:\n",
    "                os.rename(image, '/home/jupyter/kaggle_data/train/PDR/'+image)\n",
    "                print(' -> Moved to PDR')\n",
    "            except FileNotFoundError:\n",
    "                print('-> Failed to find file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n",
    "    def __init__(self, dataset, indices=None, num_samples=None):\n",
    "                \n",
    "        # if indices is not provided, \n",
    "        # all elements in the dataset will be considered\n",
    "        self.indices = list(range(len(dataset))) \\\n",
    "            if indices is None else indices\n",
    "            \n",
    "        # if num_samples is not provided, \n",
    "        # draw `len(indices)` samples in each iteration\n",
    "        self.num_samples = len(self.indices) \\\n",
    "            if num_samples is None else num_samples\n",
    "            \n",
    "        # distribution of classes in the dataset \n",
    "        label_to_count = {}\n",
    "        for idx in self.indices:\n",
    "            label = self._get_label(dataset, idx)\n",
    "            if label in label_to_count:\n",
    "                label_to_count[label] += 1\n",
    "            else:\n",
    "                label_to_count[label] = 1\n",
    "                \n",
    "        # weight for each sample\n",
    "        weights = [1.0 / label_to_count[self._get_label(dataset, idx)]\n",
    "                   for idx in self.indices]\n",
    "        self.weights = torch.DoubleTensor(weights)\n",
    "\n",
    "    def _get_label(self, dataset, idx):\n",
    "        dataset_type = type(dataset)\n",
    "        if dataset_type is torchvision.datasets.MNIST:\n",
    "            return dataset.train_labels[idx].item()\n",
    "        elif dataset_type is torchvision.datasets.ImageFolder:\n",
    "            return dataset.imgs[idx][1]\n",
    "        else:\n",
    "            return dataset.imgs[idx][1]\n",
    "                \n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in torch.multinomial(\n",
    "            self.weights, self.num_samples, replacement=True))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_MEAN = np.array([0.485, 0.456, 0.406])\n",
    "TRAIN_STD = np.array([0.229, 0.224, 0.225]) \n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        #transforms.RandomResizedCrop(224),\n",
    "        #transforms.RandomRotation(degrees=90),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(TRAIN_MEAN, TRAIN_STD)\n",
    "    ])\n",
    "\n",
    "train_dataset = datasets.ImageFolder('/home/jupyter/kaggle_data/Train/', train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(TRAIN_MEAN, TRAIN_STD)\n",
    "])\n",
    "\n",
    "val_dataset = datasets.ImageFolder('/home/jupyter/kaggle_data/Val/', val_transform)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data Dataset ImageFolder\n",
      "    Number of datapoints: 352\n",
      "    Root Location: /home/jupyter/kaggle_data/train\n",
      "    Transforms (if any): Compose(\n",
      "                             Resize(size=224, interpolation=PIL.Image.BILINEAR)\n",
      "                             RandomHorizontalFlip(p=0.5)\n",
      "                             RandomVerticalFlip(p=0.5)\n",
      "                             ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)\n",
      "                             ToTensor()\n",
      "                             Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])\n",
      "                         )\n",
      "    Target Transforms (if any): None\n",
      "train and test sizes:  281 71\n"
     ]
    }
   ],
   "source": [
    "# dataloading part\n",
    "data_dir = '/home/jupyter/kaggle_data/train'\n",
    "\n",
    "def load_split_train_test(datadir, valid_size = .1):\n",
    "    \n",
    "    TRAIN_MEAN = np.array([0.485, 0.456, 0.406])\n",
    "    TRAIN_STD = np.array([0.229, 0.224, 0.225]) \n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        #transforms.RandomCrop(224, padding=0, pad_if_needed=False),\n",
    "#        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        #transforms.RandomRotation([0, 360], resample=False, expand=False, center=None),\n",
    "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(TRAIN_MEAN, TRAIN_STD)])\n",
    "    \n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize(size=10),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(TRAIN_MEAN, TRAIN_STD)])\n",
    "    \n",
    "    train_data = datasets.ImageFolder(datadir, transform=train_transform)\n",
    "    test_data = datasets.ImageFolder(datadir, transform=test_transform)\n",
    "    \n",
    "    print(\"train_data\", train_data)\n",
    "    #num_train = len(train_data)\n",
    "    #indices = list(range(num_train))\n",
    "    #split = int(np.floor(valid_size * num_train))\n",
    "    \n",
    "    #np.random.shuffle(indices)\n",
    "    #train_idx, test_idx = indices[split:], indices[:split]\n",
    "    #train_sampler = SubsetRandomSampler(train_idx)\n",
    "    #test_sampler = SubsetRandomSampler(test_idx)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(train_data, sampler=ImbalancedDatasetSampler(train_data), batch_size=32, num_workers = 4)\n",
    "    testloader = torch.utils.data.DataLoader(test_data, sampler=ImbalancedDatasetSampler(train_data), batch_size=32, num_workers = 4)\n",
    "    \n",
    "    #trainloader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=32, num_workers = 4)\n",
    "    #testloader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=32, num_workers = 4)\n",
    "    \n",
    "    train_size = int((1-valid_size) * len(train_data))\n",
    "    test_size = len(train_data) - train_size\n",
    "    print(\"train and test sizes: \", train_size, test_size)\n",
    "    return trainloader, testloader, train_size, test_size\n",
    "\n",
    "trainloader, testloader, train_size, test_size = load_split_train_test(data_dir, .2)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#print(testloader.dataset.classes)\n",
    "classes = ('Mild_NPDR', 'Moderate_NPDR', 'Normal', 'PDR', 'Severe_NPDR')\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(testloader))\n",
    "test_iter = iter(trainloader)\n",
    "%time image_batch, label_batch = next(test_iter) \n",
    "\n",
    "# Iterate through the dataloader once\n",
    "# trainiter = iter(trainloader)\n",
    "# features, labels = next(trainiter)\n",
    "# features.shape, labels.shape\n",
    "print(image_batch.shape, image_batch.type()) \n",
    "print(label_batch.shape, label_batch.type()) \n",
    "\n",
    "TRAIN_MEAN = np.array([0.485, 0.456, 0.406])\n",
    "TRAIN_STD = np.array([0.229, 0.224, 0.225]) \n",
    "grid = torchvision.utils.make_grid(image_batch, nrow=8).cpu().numpy().transpose(1, 2, 0)\n",
    "grid = TRAIN_STD * grid + TRAIN_MEAN\n",
    "# The min and max values are very close to 0.0 and 1.0, but\n",
    "# are just outside because of numerical effects.\n",
    "grid = np.clip(grid, 0.0, 1.0)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(grid)\n",
    "#print(label_batch)\n",
    "\n",
    "label_batch = label_batch.numpy().flatten()-1\n",
    "print(label_batch)\n",
    "print(' '.join('%4s' % classes[label_batch[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfer learning model set-up\n",
    "m = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up my model with final layer customized\n",
    "\n",
    "class TruncatedResnet(torch.nn.Module):\n",
    "  \n",
    "  def __init__(self, orig_resnet):\n",
    "    super().__init__()\n",
    "    self.orig_resnet = orig_resnet\n",
    "    self.final_linear = torch.nn.Linear(512, 5) # TODO\n",
    "    #self.logsoftmax = torch.nn.LogSoftmax(dim=1)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.orig_resnet.conv1(x)\n",
    "    x = self.orig_resnet.bn1(x)\n",
    "    x = self.orig_resnet.relu(x)\n",
    "    x = self.orig_resnet.maxpool(x)\n",
    "\n",
    "    x = self.orig_resnet.layer1(x)\n",
    "    x = self.orig_resnet.layer2(x)\n",
    "    x = self.orig_resnet.layer3(x)\n",
    "    x = self.orig_resnet.layer4(x)\n",
    "\n",
    "    x = self.orig_resnet.avgpool(x)    \n",
    "    x = x.view(x.size(0), -1)\n",
    "    \n",
    "    x = self.final_linear(x) # TODO\n",
    "    #x = self.logsoftmax(x)\n",
    "    print(\"here final: \", x.size())\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading my model onto tm variable\n",
    "tm = TruncatedResnet(m)\n",
    "tm.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the optimizer\n",
    "#optimizer = torch.optim.Adam(tm.final_linear.parameters(), lr=0.001, weight_decay=0.005) # TODO\n",
    "optimizer = optim.SGD(tm.parameters(), lr=0.001, momentum=0.9)\n",
    "#exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "weights = torch.tensor([0.0275, 0.291, 0.134,  0.811, 1])\n",
    "class_weights=torch.FloatTensor(weights).cuda()\n",
    "#criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "epochs = []\n",
    "train_losses, train_errors = [], []\n",
    "val_losses, val_errors = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_for_one_epoch(model, criterion, optimizer, scheduler):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    scheduler.step()\n",
    "    model.train() # Set model to training mode\n",
    "    \n",
    "    for input_batch, label_batch in trainloader:\n",
    "        input_batch = Variable(input_batch.cuda())\n",
    "        label_batch = Variable(label_batch.cuda())\n",
    "        \n",
    "        p_batch = label_batch.float()\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            logits = model(input_batch)\n",
    "            _, preds = torch.max(logits, 1)\n",
    "            loss = criterion(logits, p_batch.long())\n",
    "            pred_batch = (logits >= 0.0).long()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            error_rate = 1.0 - (preds == label_batch).float().mean()\n",
    "            #running_loss += loss.item() * input_batch.size(0)\n",
    "            running_corrects += torch.sum(preds == label_batch.data)\n",
    "            \n",
    "        return loss.item(), error_rate.item(), running_corrects.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation function\n",
    "def val(model, criterion, optimizer, scheduler):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for image_batch, label_batch in testloader:\n",
    "        image_batch = Variable(image_batch.cuda())\n",
    "        label_batch = Variable(label_batch.cuda())\n",
    "        \n",
    "        p_batch = label_batch.float()\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            logits = model(image_batch)\n",
    "            _, preds = torch.max(logits, 1)\n",
    "            loss = criterion(logits, p_batch.long())\n",
    "            pred_batch = (logits >= 0.0).long()\n",
    "            \n",
    "            error_rate = 1.0 - (preds == label_batch).float().mean()\n",
    "            running_loss += loss.item() * image_batch.size(0)\n",
    "            running_corrects += torch.sum(preds == label_batch.data)\n",
    "            \n",
    "        return loss.item(), error_rate.item(), running_loss.item(), running_corrects.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "epochs = []\n",
    "train_losses, train_errors= [], []\n",
    "val_losses, val_errors = [], []\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(tm.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "    epochs.append(epoch)\n",
    "    train_loss, train_error, training_run_corrects = train_for_one_epoch(tm, criterion, optimizer, exp_lr_scheduler)\n",
    "    train_losses.append(train_loss)\n",
    "    train_errors.append(train_error)\n",
    "    train_epoch_loss = training_run_loss / train_size\n",
    "    train_epoch_acc = training_run_corrects / train_size\n",
    "    print(' Train Loss: {:.4f} Train Acc: {:.4f}'.format(train_epoch_loss, train_epoch_acc))\n",
    "\n",
    "    val_loss, val_error, val_run_loss, val_run_corrects = val(tm, criterion, optimizer, exp_lr_scheduler)\n",
    "    val_losses.append(val_loss)\n",
    "    val_errors.append(val_error)       \n",
    "    val_epoch_loss = val_run_loss / test_size\n",
    "    val_epoch_acc = val_run_corrects / test_size\n",
    "    print(' Val Loss: {:.4f} Val Acc: {:.4f}'.format(val_epoch_loss, val_epoch_acc))\n",
    "    \n",
    "    print(f'Epoch {epoch:3d}. Approx. train error rate: {train_error:.3f}. Val error rate: {val_error:.3f}.')\n",
    "    \n",
    "    if val_epoch_acc > best_acc:\n",
    "        best_acc = val_epoch_acc\n",
    "        best_model_wts = copy.deepcopy(tm.state_dict())\n",
    "    \n",
    "\n",
    "plot(train_losses)\n",
    "plot(train_errors)\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "#load best model weights\n",
    "tm.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "def train_for_one_epoch():\n",
    "    tm.eval()\n",
    "    \n",
    "    for input_batch, label_batch in trainloader:\n",
    "        image_batch = Variable(input_batch.cuda())\n",
    "        label_batch = Variable(label_batch.cuda())\n",
    "        label_batch = label_batch.cpu().numpy()\n",
    "        label_batch = label_batch-1\n",
    "        label_batch = Variable(torch.FloatTensor(label_batch).cuda())\n",
    "        p_batch = label_batch.long()\n",
    "      \n",
    "        logits = tm(image_batch)\n",
    "        print(logits)\n",
    "        print(\"p_batch\", p_batch)\n",
    "        _, preds = torch.max(logits, 1)\n",
    "        print(preds)\n",
    "        \n",
    "        loss = criterion(logits, p_batch)\n",
    "        print(loss)\n",
    "        #pred_batch = (logits >= 0.0).long()\n",
    "        \n",
    "        error_rate = 1.0 - (preds == p_batch).float().mean()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        return loss.item(), error_rate.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation function\n",
    "def val():\n",
    "    tm.eval()\n",
    "    image_batch, label_batch = next(iter(testloader))\n",
    "    image_batch = Variable(image_batch.cuda())\n",
    "    label_batch = Variable(label_batch.cuda())\n",
    "    label_batch = label_batch.cpu().numpy()\n",
    "    label_batch = label_batch-1\n",
    "    label_batch = Variable(torch.FloatTensor(label_batch).cuda())\n",
    "    p_batch = label_batch.long()\n",
    "    logits = tm(image_batch)\n",
    "    _, preds = torch.max(logits, 1)\n",
    "    loss = criterion(logits, p_batch)\n",
    "    \n",
    "#    pred_batch = (logits >= 0.0).long()\n",
    "    error_rate = 1.0 - (preds == p_batch).float().mean()\n",
    "    \n",
    "    return loss.item(), error_rate.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "epochs = []\n",
    "train_losses, train_errors = [], []\n",
    "val_losses, val_errors = [], []\n",
    "num_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[-0.6495, -0.6140,  0.3600,  0.3853, -0.0608],\n",
      "        [-0.6150, -0.0882,  0.2993,  0.8451, -0.5355],\n",
      "        [-0.9013,  0.0106, -0.0058,  0.0966,  0.0134],\n",
      "        [-0.1519, -0.7969,  0.3264,  0.0828, -0.5045],\n",
      "        [-0.5542, -0.0828, -0.3893,  0.2502, -0.3009],\n",
      "        [-0.6826, -0.5291,  0.0026, -0.1878, -0.5418],\n",
      "        [-0.3099, -0.4554,  0.6402, -0.2455, -0.2003],\n",
      "        [-0.6271, -0.7861, -0.4228,  0.5153,  0.0385],\n",
      "        [-0.9434, -0.3490,  0.1190,  0.5948, -0.2252],\n",
      "        [-0.4410, -0.1217,  0.2613,  0.4764, -0.7457],\n",
      "        [-0.7803,  0.0359,  0.3188, -0.1432, -0.3970],\n",
      "        [-0.4159, -0.5195,  0.2106,  0.0685, -0.2470],\n",
      "        [ 0.4693, -0.0408,  0.3598, -0.4040, -0.5803],\n",
      "        [-0.4521, -0.7365,  0.2873,  0.4296, -0.2998],\n",
      "        [ 0.2754, -0.9153,  0.4961,  0.0494, -0.2434],\n",
      "        [-0.0601, -0.7049,  0.3544,  0.2880, -0.2478],\n",
      "        [-0.6885, -0.0562,  0.1023,  0.5583, -0.0655],\n",
      "        [-0.5174, -0.8958,  0.5926,  0.1253, -0.2542],\n",
      "        [-0.4645, -0.4996,  0.3341, -0.3912, -0.3420],\n",
      "        [-0.5433, -0.3464,  0.1250,  0.3585, -0.1695],\n",
      "        [-0.4021, -0.2164, -0.0972,  0.1571, -0.3515],\n",
      "        [-0.2414, -0.8867,  0.3982, -0.4242, -0.6574],\n",
      "        [-0.3969, -0.5318,  0.0709,  0.2504, -0.2571],\n",
      "        [-0.6307, -0.2196,  0.3593, -0.2631, -0.1194],\n",
      "        [-0.3349, -0.5959,  0.1147,  0.2366, -0.3153],\n",
      "        [-0.1001, -0.5354,  0.2281, -0.2154, -0.2555],\n",
      "        [-0.7174, -0.8578,  0.3444,  0.5289, -0.1374],\n",
      "        [ 0.0246, -0.3598,  0.3332,  0.2024, -0.4590],\n",
      "        [-0.5477, -0.1533, -0.1561, -0.2414,  0.0017],\n",
      "        [ 0.1253, -0.3066,  0.5557,  0.4926,  0.1125],\n",
      "        [ 0.0860, -0.8026,  0.5292,  0.5329, -0.0388],\n",
      "        [-0.5745, -0.1238,  0.3440,  0.1237, -0.0868]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([3, 1, 1, 0, 3, 1, 2, 2, 1, 2, 4, 3, 2, 0, 2, 0, 1, 0, 3, 1, 2, 3, 2, 3,\n",
      "        3, 2, 2, 0, 2, 2, 4, 3], device='cuda:0')\n",
      "tensor([3, 3, 3, 2, 3, 2, 2, 3, 3, 3, 2, 2, 0, 3, 2, 2, 3, 2, 2, 3, 3, 2, 3, 2,\n",
      "        3, 2, 3, 2, 4, 2, 3, 2], device='cuda:0')\n",
      "tensor(1.5624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch   1. Approx. train error rate: 0.781. Val error rate: 0.812.\n",
      "Epoch 1/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[-4.0089e-01,  8.6871e-04,  3.0641e-01, -2.0593e-01, -5.3921e-01],\n",
      "        [-9.1667e-01, -8.6934e-01,  6.2442e-01,  8.1093e-02, -4.2508e-01],\n",
      "        [-7.5876e-01, -5.9029e-01, -3.8483e-02, -1.3371e-01, -8.5371e-01],\n",
      "        [-9.4985e-01, -3.1470e-01,  8.8870e-02, -2.2395e-02, -4.8921e-01],\n",
      "        [-6.9886e-01, -3.8924e-01,  2.7938e-01,  4.3616e-01, -1.7275e-01],\n",
      "        [-6.5984e-01, -3.7391e-01,  9.9409e-02,  6.9058e-01, -4.3119e-01],\n",
      "        [-3.6431e-01, -2.2872e-01,  2.1080e-01, -1.0979e-01, -6.3942e-01],\n",
      "        [-8.3538e-01,  5.5035e-01,  4.3444e-01, -2.1375e-01, -5.8023e-01],\n",
      "        [-9.1041e-01, -7.1971e-01,  4.6476e-01, -7.1397e-02, -4.8277e-01],\n",
      "        [-2.0156e-01, -9.0027e-01,  3.9130e-01,  4.8366e-01, -4.9552e-01],\n",
      "        [-4.8473e-01,  3.8556e-01,  1.9378e-02, -2.3689e-01, -5.7094e-01],\n",
      "        [-2.4514e-01, -5.2862e-01,  5.3818e-01,  8.8091e-02, -8.6572e-02],\n",
      "        [-1.8122e-01, -7.9148e-01,  5.5453e-01,  5.4129e-01, -2.7161e-01],\n",
      "        [-1.2305e-01, -5.7512e-01,  5.9824e-01, -2.7021e-01, -1.1246e+00],\n",
      "        [-2.6950e-01,  1.5969e-01,  2.6637e-01,  3.5400e-01, -3.8555e-01],\n",
      "        [ 2.3345e-01, -2.5019e-01,  9.5561e-02, -3.1156e-02, -4.9176e-01],\n",
      "        [-4.4689e-01,  1.2905e-01, -1.7359e-01, -1.5855e-02, -3.0577e-01],\n",
      "        [ 2.9204e-02, -8.3984e-01,  6.0701e-01,  6.1051e-01, -5.2400e-01],\n",
      "        [-3.3754e-01, -5.1832e-01,  2.7724e-01,  4.6613e-01, -4.2784e-01],\n",
      "        [-2.4556e-01, -3.9486e-01,  5.9227e-01,  4.4858e-02, -3.6684e-01],\n",
      "        [-4.3340e-01, -4.2779e-01,  5.4184e-01, -4.5359e-01, -5.1148e-01],\n",
      "        [-4.1876e-01, -9.4732e-02,  2.0311e-01,  4.1356e-02, -3.6375e-01],\n",
      "        [-4.6292e-01, -4.0207e-01,  4.1431e-01,  1.4386e-01, -9.0485e-01],\n",
      "        [-5.5808e-01, -5.7871e-01,  7.6726e-01, -3.8284e-01, -5.4235e-01],\n",
      "        [-5.2108e-01, -6.8232e-01,  3.0181e-01,  1.4904e-01, -4.0168e-01],\n",
      "        [-8.0785e-01, -2.2103e-01,  2.6182e-01,  1.6554e-02, -3.3408e-01],\n",
      "        [-6.6461e-01,  1.6950e-01,  1.5611e-01, -1.3935e-01, -6.0087e-01],\n",
      "        [-4.8247e-01, -4.4836e-02, -1.6647e-01, -5.5649e-02, -3.6828e-01],\n",
      "        [-5.1747e-01, -6.3148e-01,  2.0241e-01,  3.3973e-01, -3.1510e-01],\n",
      "        [-9.6954e-01, -1.7237e-01,  4.0055e-01,  8.3497e-01, -3.7046e-01],\n",
      "        [-4.7485e-01,  8.3273e-02,  5.3474e-01, -1.3614e-01, -5.0723e-01],\n",
      "        [-3.6957e-01, -8.3116e-02,  3.5213e-01, -1.4219e-01, -6.0113e-01]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([0, 3, 3, 1, 3, 1, 0, 4, 0, 0, 2, 2, 4, 0, 1, 2, 0, 0, 1, 3, 3, 4, 2, 3,\n",
      "        2, 2, 4, 4, 0, 3, 4, 4], device='cuda:0')\n",
      "tensor([2, 2, 2, 2, 3, 3, 2, 1, 2, 3, 1, 2, 2, 2, 3, 0, 1, 3, 3, 2, 2, 2, 2, 2,\n",
      "        2, 2, 1, 1, 3, 3, 2, 2], device='cuda:0')\n",
      "tensor(1.6848, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch   2. Approx. train error rate: 0.812. Val error rate: 0.812.\n",
      "Epoch 2/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[-0.9002, -0.7677,  0.4860,  0.6858, -0.4586],\n",
      "        [-0.2894, -0.0649,  0.0649, -0.0577, -0.6152],\n",
      "        [-0.4810, -0.1120,  0.0910, -0.1993, -0.4350],\n",
      "        [ 0.3033, -0.3295,  0.7030,  0.3540, -0.0749],\n",
      "        [ 0.1020, -0.4756, -0.0015,  0.5935, -0.1608],\n",
      "        [-0.6353, -0.1115,  0.0176,  0.1020, -0.3288],\n",
      "        [ 0.4360, -0.7290,  0.4345, -0.5267, -0.4444],\n",
      "        [-0.2981,  0.2049,  0.2869, -0.2787, -0.6657],\n",
      "        [ 0.2884, -0.9658,  0.4650,  0.0538, -0.3574],\n",
      "        [ 0.0570, -0.3872,  0.3265,  0.4137, -0.6537],\n",
      "        [-0.1742, -0.2403,  0.3680,  0.2639, -0.2050],\n",
      "        [-0.7145, -0.2971, -0.3672, -0.1717, -0.6155],\n",
      "        [-0.1142, -0.2124,  0.2373,  0.1160, -0.4822],\n",
      "        [ 0.3447, -0.6965,  0.0953,  0.0870, -0.4075],\n",
      "        [-0.0041, -0.3136,  0.2539, -0.4751, -0.8952],\n",
      "        [-0.6246, -0.2705, -0.1476, -0.0921, -0.2587],\n",
      "        [ 0.0805, -0.5781,  0.6679,  0.0109, -0.2930],\n",
      "        [-0.7050, -0.1225,  0.0852,  0.2716, -0.5754],\n",
      "        [-0.1822, -0.8349,  0.8433, -0.0158, -0.8929],\n",
      "        [-0.4936, -0.3116,  0.5619, -0.2749, -0.6268],\n",
      "        [-0.4932, -0.5354,  0.2048, -0.1722, -0.6441],\n",
      "        [-0.5184, -0.2959,  0.1224,  0.0201, -0.4163],\n",
      "        [ 0.1044, -0.9846,  0.7878, -0.4410, -0.4462],\n",
      "        [ 0.0020, -0.9536,  0.2618,  0.1523, -0.3520],\n",
      "        [-0.2958,  0.4403, -0.0140, -0.4179, -0.7366],\n",
      "        [-0.2405,  0.2631,  0.4616,  0.5503, -0.4867],\n",
      "        [-1.3893, -0.3973, -0.0176,  0.0106, -0.3583],\n",
      "        [-0.7008,  0.5437,  0.0979,  0.2563, -0.5803],\n",
      "        [ 0.2674, -0.7585,  0.1785, -0.4570, -0.6976],\n",
      "        [-0.1865, -0.6657,  0.3241,  0.2109, -0.2954],\n",
      "        [-0.2800,  0.1549,  0.3498, -0.1534, -0.6861],\n",
      "        [-0.0970, -0.4292,  0.3015, -0.2907, -0.4185]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([3, 3, 1, 1, 0, 3, 0, 4, 2, 0, 1, 3, 2, 2, 4, 3, 4, 4, 1, 4, 2, 3, 2, 0,\n",
      "        1, 1, 1, 2, 2, 1, 4, 1], device='cuda:0')\n",
      "tensor([3, 2, 2, 2, 3, 3, 0, 2, 2, 3, 2, 3, 2, 0, 2, 3, 2, 3, 2, 2, 2, 2, 2, 2,\n",
      "        1, 3, 3, 1, 0, 2, 2, 2], device='cuda:0')\n",
      "tensor(1.6160, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch   3. Approx. train error rate: 0.688. Val error rate: 0.750.\n",
      "Epoch 3/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[ 6.2594e-04, -2.7041e-01,  3.3615e-01, -2.0810e-01, -4.9550e-01],\n",
      "        [ 8.4243e-01, -6.6498e-01,  4.4306e-01,  3.2182e-01,  2.8678e-02],\n",
      "        [ 2.5295e-01, -4.7645e-01,  1.7924e-01, -5.9397e-02, -1.9687e-01],\n",
      "        [-7.4432e-01, -1.6279e-01,  6.8896e-02,  4.8910e-01, -3.0631e-01],\n",
      "        [ 2.7013e-01, -3.2843e-01,  2.2145e-01,  2.9958e-01, -4.0623e-02],\n",
      "        [ 4.2317e-01, -6.8297e-01,  3.6275e-01, -1.7119e-01, -4.9783e-01],\n",
      "        [-1.4586e-01,  4.8862e-01, -1.6010e-01, -1.3530e-01, -4.5282e-01],\n",
      "        [ 9.3827e-02, -1.3247e-01,  1.6507e-01, -6.4010e-02, -7.6866e-01],\n",
      "        [-3.5896e-01,  1.4496e-02, -3.1488e-02,  1.2330e-01, -3.3930e-01],\n",
      "        [-6.7733e-01, -3.4807e-01,  1.5493e-01, -9.6742e-02, -5.3588e-01],\n",
      "        [-2.9460e-01, -3.2825e-01,  1.8215e-01, -1.9425e-01, -2.8684e-01],\n",
      "        [-3.2275e-01, -9.6103e-02, -2.3306e-01, -7.4863e-01, -5.8641e-01],\n",
      "        [-2.2186e-01, -1.4581e-01, -3.2340e-01, -5.6241e-01, -3.6086e-01],\n",
      "        [-2.1317e-01, -3.4635e-01,  2.0974e-01,  7.8089e-02, -1.2057e-01],\n",
      "        [-2.3740e-02, -6.6751e-02,  1.1562e-01,  1.5589e-01, -5.1368e-01],\n",
      "        [-2.0451e-01, -1.0533e-01,  9.3747e-02, -1.4441e-01, -2.7381e-01],\n",
      "        [-3.6135e-01, -4.7241e-01,  6.7067e-01, -6.0080e-01, -4.7697e-01],\n",
      "        [-5.8419e-01, -6.9134e-02, -1.1313e-01,  1.6605e-01, -3.2110e-01],\n",
      "        [-2.1824e-02, -1.0694e-01, -9.5147e-02,  6.2505e-01,  3.4792e-01],\n",
      "        [ 1.4247e-01, -8.7431e-02,  2.0024e-01, -4.4798e-01, -6.7879e-01],\n",
      "        [ 8.0433e-01, -5.2019e-01,  6.0063e-01,  4.7257e-02, -2.6759e-01],\n",
      "        [-1.8566e-02, -1.5722e-01,  1.0534e-01, -1.9715e-01, -5.0604e-01],\n",
      "        [ 1.1812e-01, -7.5982e-01,  7.0637e-01, -7.0720e-01, -7.0844e-01],\n",
      "        [-6.0542e-02,  4.3891e-01,  2.2322e-01,  3.4218e-01, -3.4639e-01],\n",
      "        [-3.9216e-01, -4.9288e-02, -1.7302e-01, -8.4841e-02, -2.9731e-01],\n",
      "        [-3.3981e-01, -1.1437e-01,  2.6601e-01, -1.0155e-01, -3.5496e-01],\n",
      "        [-5.5121e-02, -7.6405e-04,  1.8910e-01, -2.2037e-01, -6.0251e-01],\n",
      "        [-2.5658e-01, -3.4488e-01,  1.0547e-01, -3.0551e-01, -3.8720e-01],\n",
      "        [-1.6446e-01, -1.7037e-02,  1.7195e-01, -4.0303e-01, -8.2334e-01],\n",
      "        [ 4.2426e-01, -2.5258e-01,  5.5344e-01,  3.2928e-02, -1.9053e-01],\n",
      "        [-4.1818e-01, -5.8866e-01,  4.2259e-01, -1.3245e-01, -6.0096e-01],\n",
      "        [-9.9034e-02, -4.5077e-01,  5.9868e-01,  3.3611e-01, -1.8002e-01]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([1, 2, 4, 3, 0, 2, 1, 2, 2, 1, 3, 3, 4, 4, 1, 4, 4, 0, 0, 0, 2, 1, 2, 1,\n",
      "        3, 4, 1, 1, 0, 1, 2, 4], device='cuda:0')\n",
      "tensor([2, 0, 0, 3, 3, 0, 1, 2, 3, 2, 2, 1, 1, 2, 3, 2, 2, 3, 3, 2, 0, 2, 2, 1,\n",
      "        1, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "tensor(1.5685, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch   4. Approx. train error rate: 0.812. Val error rate: 0.906.\n",
      "Epoch 4/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[-0.1079,  0.2679,  0.0380, -0.3856,  0.0072],\n",
      "        [-0.5419, -0.4598,  0.5019, -0.8028, -0.2724],\n",
      "        [ 0.3830,  0.0418, -0.0140, -0.2324, -0.2460],\n",
      "        [-0.0488, -0.0197, -0.1076, -0.4634,  0.0404],\n",
      "        [-0.0252,  0.6484, -0.3107, -0.8390, -0.4086],\n",
      "        [-0.3684,  0.5283, -0.3475, -0.1779, -0.0917],\n",
      "        [-0.3792, -0.0092,  0.2504, -1.1417, -0.5213],\n",
      "        [-0.1371, -0.0951, -0.1113, -0.4691, -0.5142],\n",
      "        [-0.0719, -0.0616,  0.3681, -0.7284, -0.3961],\n",
      "        [-0.3165, -0.0526, -0.1923,  0.2115, -0.3128],\n",
      "        [-0.2357,  0.1551,  0.1366,  0.2213, -0.2287],\n",
      "        [ 0.6274, -0.3791,  0.5018, -0.1247,  0.2164],\n",
      "        [-0.4272, -0.0850,  0.0797, -1.1665, -0.4421],\n",
      "        [-0.1171,  0.3995, -0.2440, -0.4811, -0.4786],\n",
      "        [-0.6387,  0.8771, -0.2667, -0.5889, -0.4843],\n",
      "        [ 0.0234, -0.7597,  0.4904, -0.4629, -0.2617],\n",
      "        [ 0.0450, -0.6094,  0.0795, -0.7404, -0.6213],\n",
      "        [ 0.4384, -0.2473,  0.3191, -0.1935, -0.2392],\n",
      "        [-0.0779,  0.1883, -0.0579, -0.4791, -0.5605],\n",
      "        [-0.2976,  0.2361, -0.0784,  0.3762, -0.3540],\n",
      "        [-0.2504, -0.0332, -0.2516,  0.1705, -0.3773],\n",
      "        [-0.8066,  0.4344, -0.2460, -0.0946, -0.2772],\n",
      "        [-0.1882, -0.1366,  0.2544, -0.7668, -0.3562],\n",
      "        [-0.5657,  0.0892,  0.3334, -0.1000, -0.5075],\n",
      "        [-0.0430,  0.0322, -0.0611,  0.0234,  0.0344],\n",
      "        [-0.2931,  0.2459, -0.0127, -0.5962, -0.2954],\n",
      "        [-0.3622, -0.0759,  0.0624, -1.0088, -0.5146],\n",
      "        [-0.4297, -0.8366, -0.1586, -0.4742, -0.6916],\n",
      "        [ 0.4125, -0.3912,  0.5810, -1.0230, -0.5865],\n",
      "        [ 0.2845, -0.2535,  0.1800,  0.0642,  0.1982],\n",
      "        [-0.4432,  0.1062,  0.3298, -0.3657, -0.1209],\n",
      "        [-0.3548,  0.3533, -0.1456, -0.1502, -0.0839]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([4, 2, 2, 2, 1, 2, 4, 0, 2, 3, 3, 0, 4, 1, 4, 2, 0, 0, 0, 3, 3, 1, 4, 1,\n",
      "        3, 1, 4, 2, 0, 3, 1, 2], device='cuda:0')\n",
      "tensor([1, 2, 0, 4, 1, 1, 2, 1, 2, 3, 3, 0, 2, 1, 1, 2, 2, 0, 1, 3, 3, 1, 2, 2,\n",
      "        4, 1, 2, 2, 2, 0, 2, 1], device='cuda:0')\n",
      "tensor(1.4252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch   5. Approx. train error rate: 0.562. Val error rate: 0.781.\n",
      "Epoch 5/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[-0.7173,  0.2913, -0.5517,  0.1301,  0.2854],\n",
      "        [ 0.3202,  0.2142,  0.2476, -1.2456, -0.3991],\n",
      "        [-0.5950,  0.1264, -0.2188, -0.3038, -0.1228],\n",
      "        [-0.1866, -0.2946, -0.0750, -0.4614, -0.1631],\n",
      "        [-0.0908,  0.1342,  0.2197, -0.3376, -0.0499],\n",
      "        [-0.9268,  0.0989, -0.7841,  0.1720, -0.5279],\n",
      "        [-0.5126,  0.7093, -0.5489,  0.0294,  0.1436],\n",
      "        [ 0.6567, -0.4940,  0.3350, -0.8874, -0.4195],\n",
      "        [-0.0616,  0.2948,  0.0451, -0.8334, -0.3748],\n",
      "        [-0.0277,  0.0521,  0.0568, -0.6805, -0.6007],\n",
      "        [-0.4525,  0.4361, -0.4197, -0.3370, -0.1826],\n",
      "        [ 0.2887, -0.5886, -0.0324, -0.6869, -0.1963],\n",
      "        [-0.6438, -0.0076, -0.2881, -0.2810, -0.1944],\n",
      "        [-0.1875, -0.1280,  0.2578, -1.1686, -0.1866],\n",
      "        [-0.7409,  0.0739,  0.1077, -0.9426, -0.3990],\n",
      "        [ 0.5713, -0.4794,  0.3145, -0.9829, -0.3955],\n",
      "        [-0.4355,  0.2417, -0.2203, -0.7023,  0.3223],\n",
      "        [-0.4018, -0.1141, -0.0270, -0.5924, -0.1653],\n",
      "        [-0.0093, -0.0551, -0.0596, -0.6404, -0.0719],\n",
      "        [-0.3735, -0.1345, -0.1742, -1.2108, -0.3412],\n",
      "        [ 0.1285, -0.1405, -0.0339, -0.3433, -0.3101],\n",
      "        [-0.0254,  0.4100, -0.0678, -0.6101, -0.1776],\n",
      "        [ 0.1421,  0.4630, -0.2341, -0.3993, -0.1337],\n",
      "        [ 0.2026, -0.1890,  0.1680, -0.7017, -0.0854],\n",
      "        [-0.2283, -0.0979, -0.0528, -0.7808, -0.5557],\n",
      "        [-0.6116,  0.1653,  0.1108, -1.0562,  0.1590],\n",
      "        [-0.3354, -0.1800,  0.0252, -0.2861,  0.2513],\n",
      "        [ 0.0063,  0.1057, -0.1032, -1.0095, -0.3338],\n",
      "        [-1.0737, -0.3082, -0.1146,  0.5386, -0.2202],\n",
      "        [-0.0957,  0.0092, -0.0720, -0.5025, -0.2004],\n",
      "        [-0.5593, -0.3066, -0.0605, -0.5434, -0.2562],\n",
      "        [-0.1443,  0.1727,  0.0345, -1.0388, -0.5616]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([3, 0, 3, 3, 2, 3, 3, 2, 1, 1, 0, 0, 2, 1, 1, 2, 0, 3, 1, 2, 3, 0, 1, 0,\n",
      "        4, 4, 2, 0, 3, 3, 2, 0], device='cuda:0')\n",
      "tensor([1, 0, 1, 2, 2, 3, 1, 0, 1, 2, 1, 0, 1, 2, 2, 0, 4, 2, 0, 1, 0, 1, 1, 0,\n",
      "        2, 1, 4, 1, 3, 1, 2, 1], device='cuda:0')\n",
      "tensor(1.4905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch   6. Approx. train error rate: 0.719. Val error rate: 0.656.\n",
      "Epoch 6/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[-0.2168, -0.3298,  0.0372, -1.4903, -0.3484],\n",
      "        [-0.6893, -0.1972, -0.2038,  0.5847, -0.0904],\n",
      "        [-0.6444,  0.1717, -0.1546, -1.1135, -0.4841],\n",
      "        [-0.2762, -0.0216,  0.1159, -1.1125, -0.2821],\n",
      "        [ 0.0494,  0.3232, -0.1151, -0.8288, -0.3309],\n",
      "        [-0.5705,  0.5605, -0.2758, -0.8297, -0.1011],\n",
      "        [-0.7065,  0.2414, -0.1873, -0.9582,  0.3812],\n",
      "        [ 0.0347, -0.0677,  0.0746, -0.5949, -0.2960],\n",
      "        [-0.2367,  0.2574, -0.3334,  0.6425, -0.1027],\n",
      "        [-0.1783, -0.2346, -0.0685, -0.2324, -0.1778],\n",
      "        [-0.6300,  0.3206, -0.3644, -0.8104, -0.2602],\n",
      "        [-0.6098,  0.0590, -0.5146, -0.8138, -0.2724],\n",
      "        [ 0.0166, -0.2351,  0.3597, -1.0930, -0.5339],\n",
      "        [-0.6428,  0.5458, -0.1468, -0.5634, -0.2201],\n",
      "        [-0.3683,  0.3614, -0.4414, -1.0497, -0.1794],\n",
      "        [-0.7465,  0.1174,  0.0077, -1.6899, -0.5530],\n",
      "        [ 0.1353,  0.2532, -0.0228, -1.1805, -0.5491],\n",
      "        [-0.5561,  1.0607, -0.4348,  0.0607, -0.3203],\n",
      "        [-0.3820,  0.3312, -0.6221,  0.0155, -0.1168],\n",
      "        [-0.3004,  0.0357,  0.0238, -0.8484, -0.3891],\n",
      "        [-0.5272,  0.0942, -0.3299,  0.6884,  0.1903],\n",
      "        [ 0.2084,  0.0084,  0.3432, -0.6521,  0.1997],\n",
      "        [-0.2170, -0.2556, -0.1755, -0.3583,  0.1983],\n",
      "        [-0.2321,  0.2501, -0.3635, -1.2767, -0.7427],\n",
      "        [-0.3444,  0.5171, -0.4067, -0.0829, -0.2751],\n",
      "        [-0.6935,  0.4640, -0.1927, -0.7948, -0.4467],\n",
      "        [ 0.1161,  0.1443,  0.0935, -1.2984, -0.7134],\n",
      "        [-0.1045, -0.0331, -0.2669, -0.0952, -0.2892],\n",
      "        [ 0.0696,  0.3661,  0.0906, -1.2628, -0.1173],\n",
      "        [-0.2249,  0.0748, -0.3351, -0.2149,  0.2003],\n",
      "        [ 0.3220,  0.1151,  0.0821, -0.4663,  0.4012],\n",
      "        [ 0.5781,  0.2469,  0.0149, -0.5600, -0.3357]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([3, 3, 0, 3, 2, 3, 2, 2, 3, 3, 4, 4, 1, 4, 4, 2, 0, 0, 3, 4, 3, 1, 4, 0,\n",
      "        3, 2, 2, 3, 1, 4, 0, 0], device='cuda:0')\n",
      "tensor([2, 3, 1, 2, 1, 1, 4, 2, 3, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3, 2, 4, 1,\n",
      "        1, 1, 1, 1, 1, 4, 4, 0], device='cuda:0')\n",
      "tensor(1.5821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch   7. Approx. train error rate: 0.750. Val error rate: 0.719.\n",
      "Epoch 7/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[-0.3824,  0.0139, -0.1807, -0.1551,  0.1466],\n",
      "        [-0.6252,  0.3660, -0.5526, -0.1786, -0.1828],\n",
      "        [-0.4942,  0.0659, -0.4111,  0.0795,  0.1328],\n",
      "        [-0.9201, -0.3970, -0.1439, -0.4335, -0.4660],\n",
      "        [-0.6856, -0.2659, -1.1765, -0.3899, -0.1326],\n",
      "        [-0.1339,  0.3482, -0.1982, -0.5811, -0.2568],\n",
      "        [-0.5740, -0.1068, -0.6510, -0.6884, -0.1021],\n",
      "        [-0.1391, -0.2325,  0.0625, -0.3219, -0.1101],\n",
      "        [-0.0574, -0.5901, -0.0373, -0.2008, -0.1783],\n",
      "        [-0.1183, -0.1280, -0.0631, -0.2898,  0.0920],\n",
      "        [-0.3770, -0.3382, -0.3616, -0.0809, -0.1554],\n",
      "        [-0.8016,  0.1924, -1.2038,  0.4230,  0.1533],\n",
      "        [-0.2476,  0.0948, -0.4023,  0.9228, -0.1567],\n",
      "        [-0.6009, -0.3108, -0.5814,  0.6240,  0.1061],\n",
      "        [-0.1855, -0.0557, -0.0860, -0.4814, -0.0076],\n",
      "        [ 0.1173,  0.4103, -0.3261, -0.2998, -0.1649],\n",
      "        [-0.6106, -0.1275, -1.1432,  0.0222,  0.0172],\n",
      "        [ 0.0493, -0.6224, -0.3453,  0.6944, -0.2113],\n",
      "        [-0.0304, -0.5093, -0.0203, -0.4167, -0.3759],\n",
      "        [-0.8122, -0.4457, -0.9979,  0.0722, -0.0060],\n",
      "        [-0.5322, -0.7358, -0.3683, -0.1318, -0.0689],\n",
      "        [ 1.0074, -0.4047,  0.3480, -0.6171, -0.5537],\n",
      "        [ 0.0591, -0.3859, -0.1812, -0.3420, -0.5388],\n",
      "        [ 0.4143, -0.1174, -0.0152, -0.4856, -0.1900],\n",
      "        [ 0.6396, -0.4147,  0.4341, -0.8448, -0.4169],\n",
      "        [-0.2023,  0.0712, -0.3725,  1.0222, -0.1779],\n",
      "        [-0.1360, -0.3082, -0.0824, -0.9729, -0.3324],\n",
      "        [-0.1442, -0.1320, -0.5580,  0.2442, -0.2666],\n",
      "        [ 0.1177, -0.2912,  0.4207, -0.4598, -0.3611],\n",
      "        [ 0.2744, -0.3282, -0.9965,  0.5912,  0.3138],\n",
      "        [-0.0662,  0.2822, -0.1822, -1.3156, -0.2797],\n",
      "        [ 0.5043, -0.4719,  0.3084, -0.6086, -0.4480]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([4, 4, 4, 1, 3, 0, 4, 0, 2, 1, 0, 3, 3, 3, 4, 0, 4, 3, 2, 3, 3, 2, 2, 2,\n",
      "        2, 3, 3, 3, 1, 2, 2, 0], device='cuda:0')\n",
      "tensor([4, 1, 4, 2, 4, 1, 4, 2, 2, 4, 3, 3, 3, 3, 4, 1, 3, 3, 2, 3, 4, 0, 0, 0,\n",
      "        0, 3, 2, 3, 2, 3, 1, 0], device='cuda:0')\n",
      "tensor(1.4446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch   8. Approx. train error rate: 0.562. Val error rate: 0.906.\n",
      "Epoch 8/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[-0.1771, -0.0401, -0.2914, -0.5644, -0.2291],\n",
      "        [ 0.4553, -0.9113,  0.2186, -0.2737, -0.5737],\n",
      "        [ 0.0633, -0.3314, -0.0310, -0.2413, -0.0683],\n",
      "        [-0.1187, -0.1422, -0.4565,  0.4472, -0.3463],\n",
      "        [ 0.1722, -0.6381,  0.5929, -0.0704, -0.3536],\n",
      "        [-0.3055, -0.8760,  0.0386, -0.2292, -0.3676],\n",
      "        [-0.0070, -0.5757, -0.3248,  0.0918, -0.3640],\n",
      "        [-0.5243, -0.3778, -0.7923,  1.8656,  0.1192],\n",
      "        [-0.1414, -0.7883,  0.5466, -0.1231, -0.6367],\n",
      "        [ 0.5892, -0.5698,  0.3162, -0.2070,  0.3945],\n",
      "        [ 0.4845, -0.3807,  0.1055, -0.5379, -0.2258],\n",
      "        [-0.7029, -1.0595, -0.2982,  0.6837, -0.2107],\n",
      "        [-0.3467, -0.6254, -0.4347,  0.3908, -0.1809],\n",
      "        [ 0.6308, -0.6698, -0.3611,  1.2666,  0.6007],\n",
      "        [ 0.4600, -0.6144,  0.2085, -0.7054, -0.2496],\n",
      "        [-0.5204, -0.3593, -0.3980,  0.0239, -0.0634],\n",
      "        [-0.4204, -0.6024, -0.5905,  0.7449,  0.3872],\n",
      "        [-0.0834, -0.7200, -0.2432,  1.1811,  0.0351],\n",
      "        [ 0.4198, -0.7476,  0.0898, -0.0922, -0.4259],\n",
      "        [-0.3537, -0.4996, -0.5045,  1.8062,  0.2804],\n",
      "        [-0.0073, -0.5966,  0.0130, -0.4237, -0.1326],\n",
      "        [-0.6597, -0.8139, -0.1959,  0.4580, -0.1482],\n",
      "        [-0.1921, -0.4820, -0.1880,  0.6520,  0.2395],\n",
      "        [ 0.4022, -1.2609,  0.5595, -0.3372, -0.1771],\n",
      "        [ 0.1990, -1.1895,  0.1936, -0.1730, -0.6100],\n",
      "        [ 0.4183, -0.9853, -0.2256, -0.3596,  0.1513],\n",
      "        [-0.3998, -0.6091, -0.6731,  0.7711,  0.1785],\n",
      "        [-0.3884, -0.5182, -0.7023,  1.8883,  0.1803],\n",
      "        [ 0.4155, -1.1052,  0.3541, -0.2092,  0.0543],\n",
      "        [-0.1534, -0.1664, -0.4136,  1.0181, -0.0491],\n",
      "        [-0.5026, -0.6937, -0.8133,  0.7331,  0.0766],\n",
      "        [-0.0055, -1.1187, -0.3411, -0.3183, -0.0274]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([2, 0, 1, 2, 0, 2, 4, 3, 0, 0, 1, 3, 2, 1, 2, 1, 4, 3, 0, 3, 2, 3, 4, 0,\n",
      "        1, 1, 4, 3, 1, 2, 4, 3], device='cuda:0')\n",
      "tensor([1, 0, 0, 3, 2, 2, 3, 3, 2, 0, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 2, 3, 3, 2,\n",
      "        0, 0, 3, 3, 0, 3, 3, 0], device='cuda:0')\n",
      "tensor(1.5092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch   9. Approx. train error rate: 0.656. Val error rate: 0.781.\n",
      "Epoch 9/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[ 2.2105e-02, -2.5626e-01, -7.8389e-02, -7.3744e-01, -4.6826e-01],\n",
      "        [-9.9761e-01, -5.7444e-01, -5.7106e-01,  1.1620e+00,  5.7598e-02],\n",
      "        [ 3.5373e-01, -1.1257e+00,  3.3893e-01, -1.5704e-01, -4.0976e-01],\n",
      "        [ 8.1737e-01, -7.6166e-01,  7.0580e-01, -4.9228e-01, -5.4329e-01],\n",
      "        [-5.3327e-02, -6.2063e-01, -4.6332e-02,  4.5246e-01, -5.5690e-02],\n",
      "        [-2.8325e-01, -1.1865e+00, -6.0822e-01,  8.3232e-01,  1.2387e-01],\n",
      "        [ 2.0133e-02, -5.6838e-01, -6.4825e-01, -5.1774e-02, -4.3133e-01],\n",
      "        [ 6.2118e-01, -1.2369e+00,  4.4159e-01, -3.7535e-01, -4.2276e-01],\n",
      "        [-2.9550e-01, -5.4698e-01, -6.4473e-01,  1.3649e+00,  2.7295e-02],\n",
      "        [ 5.0285e-01, -7.2597e-01, -1.2303e-01,  3.2033e-01, -1.9584e-01],\n",
      "        [ 1.7362e-01, -9.3063e-01,  4.6247e-01, -6.2466e-01, -5.4240e-01],\n",
      "        [-5.9512e-01, -4.8763e-01, -3.1689e-01,  2.2092e+00, -2.0925e-01],\n",
      "        [-8.3326e-01, -3.8679e-01, -5.0060e-01,  1.9331e+00,  2.2975e-01],\n",
      "        [-3.5259e-02, -8.2190e-01, -3.3078e-01,  1.6072e+00, -5.3117e-02],\n",
      "        [ 3.6974e-01, -9.6732e-01,  3.2901e-02,  3.9584e-01, -1.7966e-01],\n",
      "        [-2.8373e-01, -5.2194e-01, -3.5794e-01,  1.0445e+00, -6.6977e-02],\n",
      "        [-4.8082e-01, -7.4457e-01, -5.7312e-01,  1.2133e+00, -1.9658e-01],\n",
      "        [ 2.1731e-03, -3.3982e-01, -6.7355e-01,  9.2275e-01,  2.6466e-02],\n",
      "        [-6.6815e-02, -6.5262e-01, -6.5420e-01,  1.2551e+00,  2.8027e-01],\n",
      "        [ 4.9419e-01, -1.0640e+00,  2.6410e-01, -1.0402e+00, -6.4778e-01],\n",
      "        [ 2.3825e-02, -5.5364e-01, -8.4438e-02,  1.3860e+00, -2.8572e-01],\n",
      "        [-3.4590e-01, -9.8088e-01, -2.8467e-01,  6.9165e-01,  3.1663e-01],\n",
      "        [-2.0125e-01, -7.8406e-01, -3.0704e-02,  2.2987e-01, -1.1579e-01],\n",
      "        [ 2.3683e-01, -8.7658e-01,  3.5757e-01,  3.3385e-01,  1.5244e-01],\n",
      "        [-1.0720e+00, -7.1469e-01, -4.0710e-01,  1.2433e+00, -1.4089e-01],\n",
      "        [-4.4401e-01, -9.7780e-01, -3.9341e-01, -6.2781e-02, -6.4053e-01],\n",
      "        [-5.7445e-01, -1.1777e+00, -4.5955e-01,  1.2581e+00, -7.2793e-02],\n",
      "        [ 1.6134e-01, -5.9919e-01, -2.7841e-01,  2.0346e-01, -4.6017e-01],\n",
      "        [ 2.9029e-01, -1.0706e+00, -2.7362e-01,  5.3180e-01,  2.6902e-01],\n",
      "        [ 3.9036e-01, -1.1127e+00,  7.4090e-01, -6.1296e-01, -8.2282e-01],\n",
      "        [-5.5607e-01, -8.9001e-01,  9.0466e-02,  3.9069e-01, -2.5152e-01],\n",
      "        [-8.1617e-01, -7.1252e-01, -1.0306e+00,  1.8187e+00,  4.7677e-02]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([2, 0, 4, 2, 1, 2, 0, 4, 1, 1, 2, 3, 1, 3, 0, 4, 0, 0, 3, 2, 3, 4, 3, 0,\n",
      "        3, 0, 1, 1, 4, 0, 1, 3], device='cuda:0')\n",
      "tensor([0, 3, 0, 0, 3, 3, 0, 0, 3, 0, 2, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 2,\n",
      "        3, 3, 3, 3, 3, 2, 3, 3], device='cuda:0')\n",
      "tensor(1.5711, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch  10. Approx. train error rate: 0.719. Val error rate: 0.812.\n",
      "Epoch 10/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[-1.1451e+00, -8.0680e-01, -1.0520e+00,  1.4494e+00, -1.3965e-01],\n",
      "        [-5.7628e-01, -7.7319e-01, -2.2346e-01,  1.1893e+00, -1.3720e-01],\n",
      "        [ 7.3938e-01, -1.3170e+00,  5.3190e-01, -7.6990e-01, -4.9122e-01],\n",
      "        [ 4.6456e-01, -3.2850e-01,  1.8933e-01,  2.5761e-01, -3.7742e-01],\n",
      "        [-7.0450e-01, -7.2725e-01, -1.0604e+00,  7.4660e-01, -3.6609e-02],\n",
      "        [-2.9395e-01, -9.9472e-01, -2.5516e-01, -3.9306e-01, -3.8816e-01],\n",
      "        [ 7.9865e-01, -6.8099e-01,  4.9121e-01, -5.6209e-01, -5.5006e-01],\n",
      "        [ 1.6023e-01, -5.7854e-01,  8.2184e-03, -4.6087e-01, -2.5751e-01],\n",
      "        [-5.6683e-01, -5.9349e-01, -2.7433e-01,  1.1380e+00,  1.9322e-03],\n",
      "        [-2.4963e-01, -5.4876e-01, -4.4173e-01,  3.2112e-01, -1.3373e-01],\n",
      "        [-9.4260e-01, -6.5766e-01, -1.0590e+00,  1.1904e+00, -9.7032e-02],\n",
      "        [ 8.9942e-02, -4.3989e-01, -3.7418e-01, -1.9855e-01, -5.3308e-01],\n",
      "        [-1.0217e+00, -5.8347e-01, -3.9327e-01,  2.2392e+00, -2.0785e-01],\n",
      "        [-2.4250e-01, -1.4158e-01, -1.6242e-02, -3.1954e-01, -3.5157e-01],\n",
      "        [-5.3779e-01, -1.2001e+00, -6.8416e-01,  7.2303e-01,  3.3648e-01],\n",
      "        [-2.0418e-01, -1.2195e+00, -3.9591e-01,  4.1794e-01,  4.1003e-01],\n",
      "        [ 4.4407e-01, -9.8742e-01,  5.7370e-01, -4.0774e-01, -5.4042e-01],\n",
      "        [-4.8448e-01, -3.2995e-01, -5.8618e-01,  3.8023e-01, -3.2564e-01],\n",
      "        [ 3.8113e-01, -5.0207e-01,  3.0981e-01, -6.5069e-01, -4.9870e-01],\n",
      "        [-6.8423e-01, -8.1562e-01, -4.2316e-01,  2.0549e+00, -4.1386e-02],\n",
      "        [-4.3345e-01, -1.3216e+00,  3.4052e-02,  8.2065e-01, -1.6743e-01],\n",
      "        [ 6.6207e-01, -6.8104e-01,  4.1827e-01, -6.0210e-01, -4.0763e-01],\n",
      "        [-1.1104e-01, -6.5302e-01, -5.6399e-01,  2.5551e-01, -2.1151e-01],\n",
      "        [ 1.0352e-01, -6.4761e-01,  4.6848e-01, -7.8258e-01, -6.5007e-01],\n",
      "        [-2.1227e-01, -1.0938e+00, -4.3811e-01,  1.8559e-01,  1.2631e-01],\n",
      "        [ 7.5659e-01, -1.0208e+00,  5.6588e-01, -6.7348e-01, -5.6857e-01],\n",
      "        [-1.5649e-01, -2.4635e-01, -2.8061e-01, -4.8453e-02, -2.9490e-02],\n",
      "        [ 3.2104e-01, -1.0954e+00,  5.8646e-01, -2.8862e-01, -6.1124e-01],\n",
      "        [ 1.2894e-01, -8.7714e-01, -2.8222e-02,  1.6141e-01, -1.0704e-01],\n",
      "        [ 6.5960e-01, -5.3601e-01, -2.1432e-01, -1.3043e-01, -5.3192e-01],\n",
      "        [-2.5714e-01, -6.0382e-01, -3.3165e-01,  1.8473e+00,  2.6432e-01],\n",
      "        [-7.8302e-01, -2.3534e-01, -6.5300e-01,  6.9778e-01, -1.1401e-01]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([3, 1, 2, 1, 3, 2, 0, 1, 4, 4, 3, 0, 3, 2, 4, 4, 2, 4, 1, 3, 3, 1, 4, 2,\n",
      "        3, 0, 2, 2, 4, 1, 4, 1], device='cuda:0')\n",
      "tensor([3, 3, 0, 0, 3, 2, 0, 0, 3, 3, 3, 0, 3, 2, 3, 3, 2, 3, 0, 3, 3, 0, 3, 2,\n",
      "        3, 0, 4, 2, 3, 0, 3, 3], device='cuda:0')\n",
      "tensor(1.3596, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch  11. Approx. train error rate: 0.531. Val error rate: 0.750.\n",
      "Epoch 11/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[ 0.4822, -1.1819,  0.8064, -0.4415, -0.0708],\n",
      "        [ 0.2677, -0.2411,  0.4185, -0.7150, -0.4426],\n",
      "        [ 0.1841, -0.3780,  0.4385, -0.9336, -0.5986],\n",
      "        [ 0.6099, -0.5463,  0.8167, -0.9363, -0.8641],\n",
      "        [-0.2469, -0.2942, -0.5652, -0.8489, -0.6440],\n",
      "        [ 0.2261, -0.1297,  0.0991, -0.6943, -0.5068],\n",
      "        [-0.3576, -0.7094, -0.3399,  1.1043,  0.0808],\n",
      "        [-0.5160,  0.3548, -0.5385,  0.7355, -0.1915],\n",
      "        [-0.3815, -0.5625, -0.4235,  1.9720,  0.3921],\n",
      "        [-1.1819, -0.6834, -1.0364,  0.9599,  0.2169],\n",
      "        [ 0.0406, -0.8107, -0.3179, -0.0531,  0.4291],\n",
      "        [ 0.0543, -0.6036,  0.0855,  0.1208,  0.0495],\n",
      "        [-0.0826, -0.1546,  0.1245, -0.8211, -0.5372],\n",
      "        [ 0.2029, -0.1944,  0.3811, -0.7814, -0.9781],\n",
      "        [-0.5945, -0.6987, -0.4438, -0.0899,  0.0956],\n",
      "        [-0.9815, -0.2423, -0.5949,  0.1255,  0.2569],\n",
      "        [-0.2757, -0.2843,  0.0685, -0.7548, -0.6084],\n",
      "        [-0.1187, -0.5325,  0.0197, -0.2521, -0.1570],\n",
      "        [-0.1158, -0.5545,  0.5304, -0.8668, -0.4501],\n",
      "        [ 0.0161, -0.7138, -0.2793, -0.0318,  0.5771],\n",
      "        [-1.0490, -0.5141, -0.2651,  0.6574, -0.3411],\n",
      "        [-0.8996, -0.6207, -0.6424,  1.8677,  0.0599],\n",
      "        [-0.4498, -0.1163, -0.3804,  0.5314,  0.0387],\n",
      "        [-1.0799, -0.6145, -0.3781,  0.5845, -0.3756],\n",
      "        [-0.0440, -0.7390, -0.6200,  0.4984, -0.1451],\n",
      "        [ 0.3324, -0.4444, -0.4222,  0.5083,  0.2296],\n",
      "        [-1.1884, -0.2684, -1.0317,  1.6899,  0.1484],\n",
      "        [ 0.7370, -0.2771,  0.3119, -0.6215, -0.3998],\n",
      "        [-0.9412, -0.6433, -0.9023,  1.3790,  0.0467],\n",
      "        [-0.8033, -0.5419, -1.2105,  1.8094,  0.2387],\n",
      "        [-0.2558, -0.2968,  0.1666,  0.0192,  0.0564],\n",
      "        [-0.1200, -0.8604,  0.0120, -0.9852, -0.1251]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([1, 0, 0, 0, 4, 0, 3, 1, 3, 3, 4, 3, 1, 1, 3, 1, 2, 2, 1, 4, 3, 3, 4, 3,\n",
      "        3, 1, 3, 2, 3, 3, 3, 3], device='cuda:0')\n",
      "tensor([2, 2, 2, 2, 0, 0, 3, 3, 3, 3, 4, 3, 2, 2, 4, 4, 2, 2, 2, 4, 3, 3, 3, 3,\n",
      "        3, 3, 3, 0, 3, 3, 2, 2], device='cuda:0')\n",
      "tensor(1.2576, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch  12. Approx. train error rate: 0.500. Val error rate: 0.906.\n",
      "Epoch 12/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[-0.7027, -0.0407, -0.5555, -0.2930, -0.2497],\n",
      "        [ 1.0992, -0.0453,  0.2404, -0.1715, -0.1623],\n",
      "        [-1.4257, -0.4256, -0.8630,  2.4183,  0.0798],\n",
      "        [ 0.0127,  0.2280,  0.2188, -0.7662, -0.5007],\n",
      "        [-0.4406, -0.4551, -0.5725,  0.8546, -0.1342],\n",
      "        [-0.1369, -1.0368,  0.1048, -0.6501, -0.0240],\n",
      "        [-0.1214, -0.3553, -0.4140,  1.1795,  0.3160],\n",
      "        [-0.6946, -0.5240, -0.2769,  0.1116,  0.2968],\n",
      "        [-1.1847, -0.1754, -0.3328,  1.9876,  0.0433],\n",
      "        [-0.2587, -0.3958, -0.3967,  0.0695, -0.0092],\n",
      "        [ 0.1536, -0.2030,  0.7309, -1.1061, -0.3580],\n",
      "        [-0.9366,  0.0231, -1.0254,  1.0834,  0.0840],\n",
      "        [ 0.0780, -0.2912,  0.8249, -1.2620, -0.2626],\n",
      "        [-0.3756, -0.2050, -0.4306,  0.0370,  0.0402],\n",
      "        [-0.5835, -0.3164, -0.8484,  0.6048,  0.6719],\n",
      "        [-0.1187, -0.5956,  0.6717, -0.2987, -0.1461],\n",
      "        [ 0.0459,  0.1109,  0.2789, -1.4347, -0.4293],\n",
      "        [-0.4869, -0.3743, -0.5003,  1.1775,  0.0043],\n",
      "        [-1.2664, -0.3047, -1.3527,  0.8206,  0.4475],\n",
      "        [-0.5846,  0.1668,  0.3325, -0.8050, -0.5132],\n",
      "        [-0.3843, -0.0193, -0.0671, -0.2378, -0.4553],\n",
      "        [-0.8040, -0.2773, -0.6481,  0.7637,  0.8517],\n",
      "        [-0.0388,  0.1764,  0.6299, -1.2281, -0.6285],\n",
      "        [ 0.2822, -0.1147,  0.4154, -0.7569, -0.6737],\n",
      "        [-1.1494,  0.0227, -0.7104,  2.5311, -0.0603],\n",
      "        [-0.9752, -0.1926, -0.5640,  2.2498,  0.2002],\n",
      "        [-0.3205, -0.0542, -0.5222,  1.4747, -0.0061],\n",
      "        [-0.9317,  0.2128, -0.5660,  0.2241, -0.0273],\n",
      "        [-1.2189, -0.3677, -0.5679,  1.5031,  0.2001],\n",
      "        [ 0.2754, -0.0240,  0.6724, -1.3589, -0.7536],\n",
      "        [ 0.0902, -0.5479,  0.3918, -0.8199, -0.5599],\n",
      "        [-0.8235, -0.4530, -0.4300,  0.1177,  0.6121]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([4, 2, 3, 2, 3, 2, 2, 1, 3, 3, 2, 1, 2, 0, 4, 2, 1, 3, 3, 1, 0, 4, 2, 0,\n",
      "        3, 3, 3, 4, 4, 0, 0, 4], device='cuda:0')\n",
      "tensor([1, 0, 3, 1, 3, 2, 3, 4, 3, 3, 2, 3, 2, 4, 4, 2, 2, 3, 3, 2, 1, 4, 2, 2,\n",
      "        3, 3, 3, 3, 3, 2, 2, 4], device='cuda:0')\n",
      "tensor(1.1550, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch  13. Approx. train error rate: 0.469. Val error rate: 0.906.\n",
      "Epoch 13/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[-8.8547e-01,  2.0772e-01, -2.8008e-02, -3.6736e-01, -2.3337e-03],\n",
      "        [-1.7739e-01,  1.8911e-01, -1.5144e-01, -1.1226e+00, -8.2479e-01],\n",
      "        [-1.2021e+00,  1.1961e-01, -4.5369e-01, -7.5419e-02,  1.5175e-01],\n",
      "        [ 7.1139e-02,  1.7282e-01,  7.4569e-01, -1.3040e+00, -8.6742e-01],\n",
      "        [-9.2306e-01,  2.9109e-01, -4.4752e-01, -1.9464e-01, -1.5718e-01],\n",
      "        [-1.1896e+00, -6.7982e-01, -6.5937e-01,  7.3362e-02,  1.1515e-01],\n",
      "        [-4.8667e-01, -1.5991e-02,  8.5140e-01, -8.1471e-01, -4.4264e-01],\n",
      "        [-9.3497e-01,  1.1806e+00, -4.0443e-01,  4.4062e-01,  1.5950e-01],\n",
      "        [-7.1572e-01,  1.9710e-01, -2.1454e-01, -8.9242e-01, -2.8980e-01],\n",
      "        [-9.1138e-01,  2.9376e-01, -2.7396e-01, -4.6461e-01,  1.5473e-02],\n",
      "        [-1.3207e+00, -4.8044e-02, -6.6935e-01,  4.3763e-01,  6.9380e-02],\n",
      "        [-3.7754e-01,  4.3483e-01, -2.0235e-01,  3.1097e-01, -1.7075e-01],\n",
      "        [-1.2043e+00, -7.0472e-02, -6.6831e-01,  1.0173e+00,  9.3678e-01],\n",
      "        [-1.3693e-01, -2.0945e-01,  4.5886e-01, -1.1085e+00, -7.6110e-02],\n",
      "        [-1.2506e+00, -8.1558e-03, -7.3261e-01,  1.0842e+00,  1.2572e-01],\n",
      "        [ 1.2399e-01,  7.5849e-01,  2.3297e-02,  1.3752e-01,  4.5080e-01],\n",
      "        [-1.8235e+00, -5.1956e-02, -9.2423e-01,  2.3507e+00, -2.5404e-01],\n",
      "        [-8.5757e-01, -2.2831e-01, -8.1603e-01,  1.6198e+00,  6.8721e-02],\n",
      "        [-6.3894e-01,  2.7164e-01, -2.1372e-01,  4.7930e-02,  7.6345e-01],\n",
      "        [-1.0038e+00,  8.7214e-02, -1.7142e-01, -4.2530e-01, -1.2441e-01],\n",
      "        [ 1.2834e-01,  4.5839e-01,  5.5798e-01, -1.2106e+00, -6.4059e-01],\n",
      "        [-6.9045e-01,  3.5496e-01, -4.1722e-01, -4.1219e-01, -3.6721e-01],\n",
      "        [-1.4784e+00,  3.0550e-01, -5.2960e-01,  2.8303e-01,  4.1008e-01],\n",
      "        [-4.2461e-01,  9.9729e-01,  5.3350e-01, -8.9006e-01, -4.4409e-01],\n",
      "        [-1.4972e+00,  2.4294e-01, -1.1925e+00,  2.7358e+00,  4.3160e-01],\n",
      "        [-1.4614e+00, -1.2147e-01, -6.0135e-01,  7.1407e-02,  3.7719e-01],\n",
      "        [-1.4596e+00,  1.3656e-03, -1.1632e+00,  1.4635e+00,  5.8632e-02],\n",
      "        [-3.2193e-01, -8.1976e-02,  5.6331e-02, -1.0924e+00, -4.2681e-01],\n",
      "        [-6.6691e-01,  1.4568e-01, -6.0281e-01,  8.7389e-01, -5.0848e-01],\n",
      "        [-1.4222e+00, -2.1239e-01, -1.4888e+00,  8.0526e-01,  4.1624e-01],\n",
      "        [-1.5622e+00,  2.2479e-02, -8.1404e-01,  2.4362e+00,  1.7133e-01],\n",
      "        [-1.3633e+00, -3.9294e-01, -8.3736e-01,  1.6158e+00,  1.4172e-01]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([2, 2, 2, 0, 4, 4, 2, 1, 4, 4, 3, 4, 4, 1, 3, 0, 3, 3, 4, 4, 1, 2, 1, 1,\n",
      "        3, 4, 3, 2, 3, 4, 3, 3], device='cuda:0')\n",
      "tensor([1, 1, 4, 2, 1, 4, 2, 1, 1, 1, 3, 1, 3, 2, 3, 1, 3, 3, 4, 1, 2, 1, 4, 1,\n",
      "        3, 4, 3, 2, 3, 3, 3, 3], device='cuda:0')\n",
      "tensor(1.1095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch  14. Approx. train error rate: 0.500. Val error rate: 0.875.\n",
      "Epoch 14/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[-2.1349e+00,  6.7425e-01, -9.9733e-01,  2.0118e+00,  4.5296e-01],\n",
      "        [-2.0775e+00,  2.3227e-01, -8.7021e-01,  1.1949e+00,  7.6088e-01],\n",
      "        [-9.5470e-01,  1.3836e-01,  2.4778e-01, -1.2879e-01,  3.7027e-01],\n",
      "        [ 3.7369e-01,  4.8816e-01,  1.6697e+00, -2.5993e+00, -9.0283e-01],\n",
      "        [-5.5405e-01,  8.5067e-01,  1.3758e-01, -6.6821e-01, -1.4082e-01],\n",
      "        [-2.0794e+00,  5.7246e-02, -1.2444e+00,  3.0573e+00,  1.7455e-01],\n",
      "        [-1.0518e+00,  6.2857e-02, -8.9197e-01,  2.0557e+00,  2.4964e-01],\n",
      "        [-9.8003e-01, -2.6085e-04, -2.9947e-01, -7.5410e-01, -1.4582e-01],\n",
      "        [-1.4103e+00,  9.6726e-01, -3.6111e-01,  5.9952e-02, -5.7557e-03],\n",
      "        [-4.4401e-01,  3.2417e-01, -4.4442e-01, -8.6407e-01, -4.4817e-01],\n",
      "        [-9.9688e-01,  3.8375e-01, -2.1641e-01, -1.7518e-01, -1.4938e-01],\n",
      "        [-1.3707e+00, -3.3846e-01, -2.9243e-01,  6.8456e-02,  7.3506e-01],\n",
      "        [-9.8642e-02,  3.8160e-03,  6.8662e-01, -1.8288e+00, -5.5811e-01],\n",
      "        [-6.3905e-01,  8.2727e-01,  5.6784e-01, -1.1213e+00, -4.8326e-01],\n",
      "        [-4.8178e-01, -1.4962e-01, -1.5616e-02, -8.6965e-01, -6.9568e-02],\n",
      "        [-1.1098e+00,  1.2438e+00,  2.6841e-01, -7.0877e-01, -7.7839e-02],\n",
      "        [-1.5658e+00,  1.3528e-01, -3.0218e-01, -2.4431e-01,  1.5655e-01],\n",
      "        [-7.4241e-01,  2.1267e-01, -4.8133e-01,  5.9870e-01, -2.7677e-01],\n",
      "        [-1.2329e+00,  2.9375e-01, -1.3957e-01, -1.6484e-01, -3.4691e-01],\n",
      "        [ 5.5671e-01,  4.1421e-01,  1.0289e+00, -1.5509e+00, -1.8003e-01],\n",
      "        [-6.9209e-01,  2.9533e-01, -2.6746e-01, -1.0200e+00, -5.9854e-01],\n",
      "        [-7.6976e-01,  5.0054e-02,  1.9784e-01, -8.5001e-01, -2.9056e-01],\n",
      "        [-7.8628e-01,  1.4161e+00,  3.6110e-02, -2.6295e-01,  3.7332e-01],\n",
      "        [-1.7261e+00, -1.0646e-02, -1.4814e+00,  1.1498e+00,  5.1882e-01],\n",
      "        [-7.8412e-01,  1.3050e-02,  2.1862e-01, -7.3757e-01, -2.0767e-01],\n",
      "        [-2.1566e+00, -5.9919e-02, -1.5250e+00,  1.2318e+00,  8.5501e-01],\n",
      "        [-8.0459e-01,  5.7333e-01,  8.3187e-02, -1.3861e+00, -1.4961e-01],\n",
      "        [-8.2908e-01,  3.0919e-01, -5.5931e-01,  4.5793e-01,  4.0408e-01],\n",
      "        [-1.8430e+00,  3.4759e-01, -1.1799e+00,  3.1009e+00,  5.4716e-01],\n",
      "        [-1.2595e+00, -4.1863e-01, -3.5794e-01, -5.0875e-01,  6.0511e-01],\n",
      "        [-1.2081e+00,  5.7182e-01, -7.5650e-01,  1.8475e-01,  7.0407e-01],\n",
      "        [-3.8086e-01,  7.2666e-01, -9.9749e-02, -9.9829e-01, -2.1485e-01]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([3, 1, 2, 2, 0, 3, 3, 4, 1, 0, 4, 4, 2, 0, 0, 1, 3, 3, 2, 0, 0, 4, 2, 3,\n",
      "        3, 1, 1, 2, 3, 4, 4, 1], device='cuda:0')\n",
      "tensor([3, 3, 4, 2, 1, 3, 3, 1, 1, 1, 1, 4, 2, 1, 2, 1, 4, 3, 1, 2, 1, 2, 1, 3,\n",
      "        2, 3, 1, 3, 3, 4, 4, 1], device='cuda:0')\n",
      "tensor(1.2761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch  15. Approx. train error rate: 0.531. Val error rate: 0.812.\n",
      "Epoch 15/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[-0.3017,  0.2694,  0.9817, -1.8866, -0.6177],\n",
      "        [ 0.8250, -0.0101,  1.0858, -1.7813, -0.0449],\n",
      "        [-0.3355,  0.0518,  0.9491, -1.3765,  0.0545],\n",
      "        [-1.8741,  0.3026, -0.5053,  0.0406,  1.2430],\n",
      "        [-0.7587,  0.3246,  0.8625, -2.0200, -0.7698],\n",
      "        [-1.1579, -0.3344, -0.5498,  0.2795,  0.7634],\n",
      "        [-0.5214,  0.0459,  0.1547, -0.9660,  0.4051],\n",
      "        [-1.7786, -0.0471, -0.6108, -0.4814,  1.0543],\n",
      "        [ 0.0152,  0.0432,  1.3307, -2.4846, -0.5705],\n",
      "        [-0.9538,  0.2137, -0.4058, -0.1667,  0.5279],\n",
      "        [-1.7247,  0.0213, -1.2171,  1.0004,  0.5525],\n",
      "        [-1.4794, -0.3019, -1.0293,  0.6683,  0.6501],\n",
      "        [-0.6539,  0.0134,  0.8968, -1.7705, -0.0448],\n",
      "        [-0.0552,  0.6337,  0.8235, -1.9721, -0.2526],\n",
      "        [-2.1827, -0.6213, -1.2526,  2.1143,  0.7745],\n",
      "        [-1.8772, -0.0212, -0.3869,  0.2790,  0.4052],\n",
      "        [-0.2506,  0.1924,  0.8746, -1.5782, -0.4234],\n",
      "        [-0.6550, -0.1167,  0.6175, -1.4609,  0.0841],\n",
      "        [-0.8509,  0.5121,  0.8111, -1.9711, -0.6718],\n",
      "        [-1.8687,  0.0834, -0.0838, -0.6988,  0.9813],\n",
      "        [-0.7032, -0.4569, -0.8569,  0.2974,  0.2025],\n",
      "        [ 0.6308,  0.1263,  0.9890, -1.9918, -0.3305],\n",
      "        [ 0.2785,  0.3023,  0.6008, -1.6344, -0.0580],\n",
      "        [-0.9713,  0.0326, -0.2999, -0.8091, -0.0602],\n",
      "        [-1.4307, -0.2655, -0.8833, -0.1465,  1.0404],\n",
      "        [-0.9796, -0.0787, -0.5622,  0.4279,  0.2905],\n",
      "        [-1.2495, -0.4260, -0.5384, -0.1408,  0.7052],\n",
      "        [-0.8068, -0.3906, -1.0644,  1.0606,  0.6876],\n",
      "        [-1.6390, -0.2799, -0.4526,  0.3710,  0.2184],\n",
      "        [-1.6218, -0.1401, -0.0204, -0.4807,  1.2125],\n",
      "        [-2.4593, -0.3921, -1.1064,  2.7649,  0.4491],\n",
      "        [ 0.0425, -0.1211,  0.6276, -1.7387, -0.1624]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([1, 0, 2, 4, 0, 4, 2, 4, 1, 4, 1, 1, 2, 2, 3, 3, 2, 2, 1, 4, 3, 0, 0, 4,\n",
      "        4, 3, 4, 3, 3, 4, 3, 2], device='cuda:0')\n",
      "tensor([2, 2, 2, 4, 2, 4, 4, 4, 2, 4, 3, 3, 2, 2, 3, 4, 2, 2, 2, 4, 3, 2, 2, 1,\n",
      "        4, 3, 4, 3, 3, 4, 3, 2], device='cuda:0')\n",
      "tensor(1.0540, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch  16. Approx. train error rate: 0.375. Val error rate: 0.812.\n",
      "Epoch 16/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[-9.4130e-01, -2.3858e-01, -9.9672e-01,  2.0895e-01,  2.3959e-01],\n",
      "        [-9.6810e-01, -2.4724e-01,  6.7365e-02, -1.3681e+00,  4.7438e-01],\n",
      "        [-4.4083e-01,  4.8235e-01,  8.1903e-01, -2.2001e+00,  2.8466e-02],\n",
      "        [-8.3466e-01, -1.3353e-01, -3.1841e-01, -9.0507e-01,  6.0154e-01],\n",
      "        [ 1.7811e-01, -6.1056e-01,  4.8540e-01, -1.1271e+00, -2.8200e-01],\n",
      "        [-1.7357e+00, -2.1819e-01, -7.5223e-01,  8.1536e-01,  9.0725e-01],\n",
      "        [-8.3670e-01, -1.7761e-01, -1.2462e-01, -1.0889e+00, -2.1834e-01],\n",
      "        [-7.3797e-01, -2.2338e-01,  5.4353e-01, -1.1812e+00, -1.3925e-01],\n",
      "        [-8.4182e-03, -2.9444e-01,  1.2379e+00, -2.7817e+00, -2.9370e-01],\n",
      "        [-1.1043e-01, -2.0126e-01,  9.3217e-01, -2.0655e+00, -7.1735e-01],\n",
      "        [-8.2121e-01,  4.4325e-01,  2.9683e-02, -1.1100e+00,  2.9897e-01],\n",
      "        [-1.1260e+00, -1.1701e-01, -6.4867e-01, -4.5295e-01,  6.6211e-01],\n",
      "        [ 2.6790e-02, -7.9206e-01,  7.6758e-01, -2.0747e+00,  5.8894e-01],\n",
      "        [ 5.3771e-01, -3.0184e-01,  1.3136e+00, -2.6076e+00, -5.8156e-01],\n",
      "        [-1.1078e-01,  3.3487e-02,  1.0938e+00, -2.0808e+00, -5.1633e-01],\n",
      "        [ 5.3746e-01, -3.3852e-02,  1.2045e+00, -2.2782e+00, -3.0459e-01],\n",
      "        [ 8.9128e-02, -1.7783e-01,  1.0189e+00, -2.6678e+00, -1.3923e-02],\n",
      "        [ 2.5081e-01, -2.4916e-01,  7.6864e-01, -2.0762e+00, -2.9526e-01],\n",
      "        [-2.6680e-01, -4.7292e-01,  2.1603e-01, -1.0497e+00,  1.1452e-01],\n",
      "        [-1.0732e+00, -1.0807e-01, -7.2405e-01, -4.7072e-01,  1.0414e+00],\n",
      "        [-1.0452e-01, -6.2685e-01,  1.4056e+00, -2.9011e+00, -1.7294e-03],\n",
      "        [-3.7341e-01, -5.2757e-01,  6.7133e-01, -2.3754e+00,  1.8845e-01],\n",
      "        [-4.7453e-01,  4.3486e-01,  4.8936e-01, -9.8635e-01,  7.5384e-01],\n",
      "        [-2.3264e+00, -3.3263e-01, -1.0344e+00,  2.5845e+00,  9.8621e-01],\n",
      "        [-1.1577e+00,  2.5544e-03, -5.8169e-01,  1.6821e+00,  4.2158e-01],\n",
      "        [-1.5795e+00, -5.3911e-01, -9.9711e-01, -2.2487e-01,  1.5788e+00],\n",
      "        [-1.1065e+00, -6.6308e-01, -5.9717e-01,  1.5132e+00,  6.2295e-01],\n",
      "        [-2.1509e+00, -7.1516e-01, -1.1597e+00,  2.4610e+00,  1.1167e+00],\n",
      "        [-1.5146e+00, -5.2748e-01, -5.7435e-01, -1.4843e-01,  7.4144e-01],\n",
      "        [ 4.4018e-02, -2.5108e-01,  1.1519e+00, -2.1012e+00, -3.6385e-01],\n",
      "        [-2.1970e+00, -2.0751e-01, -1.0557e+00,  2.9147e+00,  1.0666e+00],\n",
      "        [-1.9003e+00, -4.2182e-01, -1.1208e+00,  2.9212e+00,  5.4233e-01]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([2, 4, 1, 4, 2, 2, 0, 2, 1, 2, 2, 2, 2, 0, 0, 2, 1, 0, 0, 4, 2, 4, 1, 3,\n",
      "        3, 4, 3, 3, 0, 0, 3, 3], device='cuda:0')\n",
      "tensor([4, 4, 2, 4, 2, 4, 2, 2, 2, 2, 1, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 3,\n",
      "        3, 4, 3, 3, 4, 2, 3, 3], device='cuda:0')\n",
      "tensor(1.2166, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch  17. Approx. train error rate: 0.500. Val error rate: 0.656.\n",
      "Epoch 17/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[ 0.4725, -0.5283,  1.2572, -1.9689, -0.4709],\n",
      "        [ 0.0536, -0.7814, -0.6122,  0.0595,  0.4289],\n",
      "        [ 0.1051, -0.8959,  0.8552, -2.0916,  0.2860],\n",
      "        [ 1.0259, -1.1691,  1.1155, -2.5051, -0.1674],\n",
      "        [ 0.0497, -0.2982,  0.6147, -2.0888, -0.5780],\n",
      "        [-0.5492, -0.4743,  0.0289, -0.7666,  0.4744],\n",
      "        [ 1.1728, -0.1861,  0.9209, -2.0172, -0.1446],\n",
      "        [ 1.1371, -0.2424,  1.7175, -3.1611, -0.3663],\n",
      "        [ 0.6432, -0.3222,  0.7943, -2.3715, -0.7031],\n",
      "        [ 0.2149, -0.2245,  0.8402, -1.6326,  0.1093],\n",
      "        [ 0.6017, -0.6312,  1.3419, -2.8525, -0.5953],\n",
      "        [ 0.1299, -0.0753,  0.3665, -1.2962, -0.1994],\n",
      "        [-0.7701, -0.6357, -0.0590, -1.0026,  0.4387],\n",
      "        [ 1.5549, -1.3692,  1.0282, -2.5827, -0.0781],\n",
      "        [-0.2510, -0.3085,  0.5060, -0.7895,  0.1008],\n",
      "        [-0.3708, -0.9649, -0.3988, -0.7792,  1.3065],\n",
      "        [-1.2896, -1.0639, -0.5850, -0.4464,  0.9493],\n",
      "        [-0.8923, -0.6306, -0.3896,  0.2873,  0.6973],\n",
      "        [-0.6205, -0.1277, -0.7620,  1.2378,  0.4615],\n",
      "        [ 0.5742, -0.3246,  1.2845, -2.6618, -0.6749],\n",
      "        [-2.0955, -0.3791, -1.0894,  1.7188,  0.8307],\n",
      "        [ 1.6222, -0.4244,  1.8849, -3.4469, -0.6146],\n",
      "        [ 1.3923, -0.7147,  2.0545, -3.5368, -0.5978],\n",
      "        [-0.7242, -0.8407, -0.5757, -0.1374,  0.7993],\n",
      "        [-0.5313, -0.6292,  0.4839, -2.3240, -0.1792],\n",
      "        [-0.0775, -0.5804,  0.7541, -1.8031,  0.1751],\n",
      "        [-0.9258, -0.4091, -0.2817,  1.1734,  0.4730],\n",
      "        [-0.5891, -0.8500, -0.0557, -0.8612,  0.4455],\n",
      "        [-0.2986, -0.8315, -0.2787, -1.4612,  0.3930],\n",
      "        [ 0.3111, -0.7108,  0.9692, -1.8024, -0.4837],\n",
      "        [-1.5989, -0.9713, -0.3172, -0.2828,  1.1895],\n",
      "        [-1.0942, -0.5913, -0.5032, -0.4255,  1.2956]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([0, 3, 1, 1, 0, 4, 0, 2, 0, 1, 1, 0, 3, 2, 1, 1, 0, 1, 0, 2, 3, 0, 2, 0,\n",
      "        0, 1, 3, 1, 4, 2, 3, 1], device='cuda:0')\n",
      "tensor([2, 4, 2, 2, 2, 4, 0, 2, 2, 2, 2, 2, 4, 0, 2, 4, 4, 4, 3, 2, 3, 2, 2, 4,\n",
      "        2, 2, 3, 4, 4, 2, 4, 4], device='cuda:0')\n",
      "tensor(1.6457, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch  18. Approx. train error rate: 0.719. Val error rate: 0.844.\n",
      "Epoch 18/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[ 5.2644e-01, -8.3184e-01, -7.5314e-01, -1.3951e+00, -2.8161e-01],\n",
      "        [-1.7113e+00, -7.4237e-02, -1.4889e+00,  1.6396e+00,  4.4017e-01],\n",
      "        [ 1.0475e-01, -4.3540e-01, -2.9190e-01, -1.7334e+00, -1.4575e-01],\n",
      "        [ 1.7870e-01, -6.2847e-01, -4.1130e-01, -1.2362e+00, -6.1503e-02],\n",
      "        [-1.8512e+00, -4.9415e-01, -1.3501e+00,  2.8790e+00,  7.0225e-01],\n",
      "        [ 4.5074e-01, -6.8940e-01, -3.3926e-01, -7.1550e-01,  1.4289e-02],\n",
      "        [-8.2689e-01, -7.7081e-01, -1.3078e+00,  2.1811e-01,  1.2435e+00],\n",
      "        [ 1.3776e+00, -1.0894e-02,  1.5856e+00, -3.0012e+00, -7.9760e-01],\n",
      "        [ 3.4370e-01,  1.7762e-02,  6.2499e-02, -7.8767e-01, -5.3889e-01],\n",
      "        [ 2.7470e-03, -6.1260e-01, -5.1002e-01, -5.4989e-01,  1.9597e-01],\n",
      "        [ 3.1419e-01,  2.2882e-01,  5.9534e-01, -2.5088e+00, -6.8846e-01],\n",
      "        [ 9.5757e-01, -1.0476e-01,  1.1965e+00, -3.1453e+00, -1.0342e+00],\n",
      "        [-5.5350e-03, -4.9323e-01, -5.7295e-01, -6.1054e-01,  2.1771e-01],\n",
      "        [-6.5338e-01, -1.8229e-01, -6.7376e-01,  8.6246e-02,  2.8825e-01],\n",
      "        [-3.6523e-01, -1.5594e-01,  5.1309e-01, -7.9624e-01, -4.5055e-01],\n",
      "        [ 1.7513e+00, -2.5648e-01,  1.5767e+00, -2.6729e+00, -8.8045e-01],\n",
      "        [ 8.0216e-01, -1.3524e-01,  8.7429e-01, -2.6486e+00, -9.1264e-01],\n",
      "        [ 4.4253e-02, -3.1325e-01, -3.0686e-01, -2.5597e-01,  6.2131e-02],\n",
      "        [ 1.0962e+00, -3.9279e-01,  7.1224e-01, -2.9867e+00, -1.5408e+00],\n",
      "        [ 2.1469e-01, -4.4947e-01, -3.3211e-01, -1.3812e+00, -1.4542e-01],\n",
      "        [-2.1772e+00,  5.1836e-02, -1.5267e+00,  1.6036e+00,  6.7153e-01],\n",
      "        [ 1.5750e+00, -5.7098e-01,  1.0584e+00, -2.7562e+00, -1.0002e+00],\n",
      "        [ 7.8280e-01, -5.4022e-01,  4.0784e-01, -1.9899e+00, -2.9179e-01],\n",
      "        [ 2.0072e+00, -5.5492e-01,  1.3616e+00, -3.0032e+00, -1.0902e+00],\n",
      "        [-1.2600e+00, -3.6725e-02, -8.6568e-01,  1.0596e+00,  4.7281e-01],\n",
      "        [ 7.5773e-02, -2.2786e-01,  6.9108e-02, -4.5166e-01,  1.0622e-02],\n",
      "        [ 1.6344e-01, -2.5692e-01, -3.9710e-01, -5.5525e-01,  4.8048e-03],\n",
      "        [-4.8127e-01,  1.5117e-01, -2.7619e-01, -4.7083e-01, -2.1859e-01],\n",
      "        [ 1.1743e+00, -5.4759e-01,  6.6215e-01, -1.8579e+00, -1.5251e-01],\n",
      "        [-1.1995e+00,  1.0859e-01, -1.6396e+00,  5.1409e-01,  1.1021e+00],\n",
      "        [ 1.6342e-01, -3.7095e-01, -2.6561e-01, -3.5406e-01,  1.9519e-01],\n",
      "        [ 5.2595e-01,  1.8299e-01,  1.8770e-01, -1.1860e+00, -5.9761e-01]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([4, 3, 4, 4, 3, 0, 4, 1, 2, 3, 2, 1, 4, 1, 2, 0, 2, 3, 0, 4, 3, 1, 4, 0,\n",
      "        4, 1, 4, 2, 0, 4, 2, 0], device='cuda:0')\n",
      "tensor([0, 3, 0, 0, 3, 0, 4, 2, 0, 4, 2, 2, 4, 4, 2, 0, 2, 4, 0, 0, 3, 0, 0, 0,\n",
      "        3, 0, 0, 1, 0, 4, 4, 0], device='cuda:0')\n",
      "tensor(1.2726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch  19. Approx. train error rate: 0.531. Val error rate: 0.750.\n",
      "Epoch 19/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[-0.6345, -0.1739, -0.5568, -1.3773,  0.1510],\n",
      "        [-0.5069,  0.1181, -1.0306,  0.0052,  0.0474],\n",
      "        [ 0.1959, -0.1495, -0.3022, -1.5767,  0.3867],\n",
      "        [-0.5664, -0.1377, -1.3527,  0.5746,  0.6737],\n",
      "        [-0.7626,  0.3686, -0.9576,  0.0933,  0.5833],\n",
      "        [ 1.6772, -0.0062,  0.8010, -2.9966, -1.3277],\n",
      "        [ 1.7813,  0.4544,  0.8761, -3.1395, -0.9421],\n",
      "        [ 0.2165,  0.0480,  0.0078, -1.1603, -0.1545],\n",
      "        [ 0.8764,  0.2655,  0.5820, -2.8148, -1.2511],\n",
      "        [-0.4571, -0.6042, -1.3070,  0.4643,  0.6177],\n",
      "        [ 0.2366, -0.1104, -0.3333, -1.6250, -0.9920],\n",
      "        [ 0.4003,  0.2240, -0.9903, -0.2495, -0.0873],\n",
      "        [-0.8949, -0.0958, -1.6448, -0.2076,  1.0878],\n",
      "        [ 1.1378,  0.3020,  1.0918, -2.8631, -1.4857],\n",
      "        [-0.2660, -0.3142, -1.0044,  1.3009,  0.1118],\n",
      "        [-1.0071, -0.0033, -1.1465,  1.2322,  0.2192],\n",
      "        [ 1.7618,  0.0559,  0.6271, -2.4456, -0.4296],\n",
      "        [ 0.4557,  0.2888,  0.0275, -2.2030, -0.8814],\n",
      "        [-0.2799, -0.1844, -1.0829, -0.0336,  0.2108],\n",
      "        [ 0.9261,  0.3440,  0.7351, -2.5764, -1.0846],\n",
      "        [-1.7891,  0.0154, -2.0113,  2.7324,  0.4505],\n",
      "        [ 0.3540, -0.1375, -0.6647, -1.3857, -0.2145],\n",
      "        [ 0.0901, -0.2444, -0.8017, -0.5213,  0.1842],\n",
      "        [-0.7348,  0.2789, -1.2455,  0.3392,  0.9735],\n",
      "        [-0.6824,  0.1505, -0.6882, -0.3759, -0.0943],\n",
      "        [ 1.7241,  0.4946,  0.6628, -2.3933, -0.9652],\n",
      "        [-1.3427, -0.2524, -1.9291,  0.7180,  0.7942],\n",
      "        [ 0.5038,  0.2020,  0.5051, -1.6545, -0.8917],\n",
      "        [ 1.1758, -0.3144,  0.4436, -2.0628, -1.0815],\n",
      "        [-0.6049,  0.2810, -0.5338, -0.9077,  0.3092],\n",
      "        [ 0.7590,  0.4808,  0.0078, -2.1681, -0.6989],\n",
      "        [ 0.7200, -0.5805, -0.4007, -1.6024, -0.4400]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([2, 4, 2, 3, 4, 0, 0, 4, 1, 0, 0, 1, 4, 1, 3, 3, 0, 2, 4, 0, 3, 2, 4, 4,\n",
      "        4, 0, 4, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "tensor([4, 1, 4, 4, 4, 0, 0, 0, 0, 4, 0, 0, 4, 0, 3, 3, 0, 0, 4, 0, 3, 0, 4, 4,\n",
      "        1, 0, 4, 2, 0, 4, 0, 0], device='cuda:0')\n",
      "tensor(1.1438, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch  20. Approx. train error rate: 0.500. Val error rate: 0.688.\n",
      "Epoch 20/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[-2.6342, -0.1824, -2.7444,  3.7639,  0.8187],\n",
      "        [-0.0424, -0.3941, -0.9482,  0.2669,  0.4897],\n",
      "        [-1.2047, -0.2655, -1.9118,  2.2261,  0.7203],\n",
      "        [-0.3009,  0.8434, -0.9733, -1.0968, -0.0209],\n",
      "        [-1.4748, -0.2787, -1.6175,  3.5843,  0.3134],\n",
      "        [-1.8649,  0.0699, -2.5116,  0.6058,  1.4954],\n",
      "        [-1.9939, -0.1342, -2.4229,  2.2925,  0.8593],\n",
      "        [-0.6905,  0.2902, -1.8882,  0.7058,  0.4766],\n",
      "        [ 0.0717,  0.7013, -0.5842, -1.6274, -0.4268],\n",
      "        [-1.8170, -0.7890, -2.3184,  1.7587,  1.0320],\n",
      "        [-1.7460,  0.1267, -2.4457,  0.7955,  1.2273],\n",
      "        [ 0.4213,  0.1547, -1.6878,  0.0789, -0.1057],\n",
      "        [-0.0094,  0.9959, -0.5811, -1.7218, -0.2934],\n",
      "        [-1.0913,  0.4794, -1.9957,  0.7497,  1.5402],\n",
      "        [ 0.4631,  0.8742, -0.6834, -2.5828, -0.2590],\n",
      "        [-0.8374,  0.0997, -1.7815,  0.1241,  0.5134],\n",
      "        [-0.2672, -0.0782, -0.6680, -0.4598, -0.0115],\n",
      "        [-1.6679, -0.2152, -2.1523,  0.8192,  1.5136],\n",
      "        [ 0.4227,  0.6473,  0.0246, -2.5635, -0.6798],\n",
      "        [-2.3505,  0.0555, -2.3670,  3.1715,  0.9323],\n",
      "        [ 0.3681,  0.9982, -0.0839, -1.8819, -0.4323],\n",
      "        [ 1.4987,  0.8123,  0.1715, -3.8278, -1.0215],\n",
      "        [-0.0145,  0.4165, -0.7389, -0.9329, -0.3927],\n",
      "        [-1.3065,  0.0726, -1.3642,  0.9975,  0.5201],\n",
      "        [-1.9352,  0.0566, -2.3955,  2.8401,  0.7380],\n",
      "        [-1.0771, -0.6368, -1.6030,  2.6796,  0.5211],\n",
      "        [-1.8842, -0.0213, -2.3393,  1.0166,  1.5395],\n",
      "        [-0.9793,  0.6165, -1.6101, -0.2978,  0.5096],\n",
      "        [-1.2620, -0.0952, -1.4882,  0.8163,  0.8298],\n",
      "        [-0.8961, -0.1460, -1.4336,  0.5204,  0.9071],\n",
      "        [-1.4706,  0.6678, -2.6771,  1.2226,  1.1699],\n",
      "        [-0.7127,  0.2229, -1.5507,  0.2057,  0.5823]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([3, 1, 3, 2, 3, 4, 3, 4, 2, 4, 4, 2, 1, 4, 0, 1, 2, 4, 0, 3, 1, 0, 1, 2,\n",
      "        3, 3, 4, 1, 3, 4, 1, 4], device='cuda:0')\n",
      "tensor([3, 4, 3, 1, 3, 4, 3, 3, 1, 3, 4, 0, 1, 4, 1, 4, 4, 4, 1, 3, 1, 0, 1, 3,\n",
      "        3, 3, 4, 1, 4, 4, 3, 4], device='cuda:0')\n",
      "tensor(1.0608, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch  21. Approx. train error rate: 0.406. Val error rate: 0.781.\n",
      "Epoch 21/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[-2.0895e+00,  1.4126e-01, -2.9629e+00,  2.9606e+00,  7.3067e-01],\n",
      "        [-1.6246e-01,  3.8927e-01, -1.0352e+00, -8.5027e-01, -1.2820e-01],\n",
      "        [-6.4169e-01,  6.0095e-01, -1.2231e+00, -1.4685e+00,  2.5232e-01],\n",
      "        [-1.3671e+00, -1.6766e-01, -2.3790e+00,  2.3732e+00,  1.3889e+00],\n",
      "        [ 1.9857e+00,  1.0069e+00,  1.1245e-01, -3.3237e+00, -7.7066e-01],\n",
      "        [-1.6081e+00,  6.8243e-02, -1.5110e+00,  6.2245e-01,  1.0094e+00],\n",
      "        [-4.3652e-01,  7.6862e-01, -5.9816e-01, -2.1975e+00, -8.5197e-01],\n",
      "        [-2.1129e+00,  4.9318e-01, -2.9542e+00,  6.6451e-01,  1.6789e+00],\n",
      "        [-6.5863e-01, -1.3428e-01, -1.6709e+00,  9.8700e-01,  5.0101e-01],\n",
      "        [-1.4471e+00,  3.4640e-01, -1.3488e+00,  1.8968e-01,  5.1914e-01],\n",
      "        [-2.4718e-01,  1.1122e+00, -9.4026e-01, -1.5838e+00,  4.6726e-02],\n",
      "        [-4.6478e-01,  5.4795e-04, -1.6453e+00, -5.7259e-01,  6.3592e-01],\n",
      "        [-1.1492e-01,  1.7766e-01, -1.2478e+00, -1.7816e+00,  7.0639e-01],\n",
      "        [-9.6242e-01,  1.2544e-01, -1.8182e+00,  3.1562e-01,  1.0502e+00],\n",
      "        [-6.3209e-01, -2.0382e-01, -6.8084e-01, -1.2747e+00, -2.5148e-01],\n",
      "        [-1.7597e-01,  9.5860e-01, -8.8222e-01, -1.0945e+00, -1.1097e-02],\n",
      "        [-8.4463e-01, -2.2622e-01, -1.0472e+00,  4.4006e-02,  5.2000e-01],\n",
      "        [-8.2979e-01,  1.0550e-01, -1.2401e+00, -1.2411e-01,  4.3238e-01],\n",
      "        [ 9.7474e-02, -1.7244e-01, -1.0446e+00, -1.4711e+00,  2.8479e-01],\n",
      "        [-8.2069e-01,  3.8009e-01, -1.5119e+00,  1.1707e+00,  5.0097e-01],\n",
      "        [-1.2599e+00, -7.5474e-02, -1.4540e+00,  7.1588e-01,  9.8439e-01],\n",
      "        [-1.1105e+00, -1.0097e-01, -1.7219e+00,  6.0114e-01,  1.3047e+00],\n",
      "        [-1.5811e+00,  1.0926e-01, -1.7855e+00,  1.5119e+00,  1.0836e+00],\n",
      "        [-2.5533e+00,  3.1820e-01, -1.8535e+00,  3.1987e+00,  1.1754e+00],\n",
      "        [-1.8261e-01,  1.9557e-01, -1.0659e+00, -3.2367e-01,  2.9577e-01],\n",
      "        [-1.1204e+00, -8.9113e-02, -2.0669e+00,  6.7685e-01,  1.0021e+00],\n",
      "        [-1.5422e+00,  1.9258e-01, -1.2558e+00,  1.2459e+00,  4.2846e-01],\n",
      "        [-2.3979e+00, -8.1131e-02, -2.4854e+00,  2.7155e+00,  7.8148e-01],\n",
      "        [-3.4106e-01,  5.7315e-02, -1.5408e+00, -1.1124e+00,  6.6314e-01],\n",
      "        [ 2.3063e-01,  6.6597e-01, -7.6485e-01, -2.4122e+00, -5.8951e-01],\n",
      "        [ 1.0871e+00,  9.6836e-01, -3.8323e-01, -2.9387e+00, -5.2419e-01],\n",
      "        [ 6.1350e-01,  1.9251e-01, -4.1025e-01, -1.8119e+00, -2.8752e-01]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([3, 2, 2, 3, 0, 2, 0, 1, 0, 1, 1, 1, 4, 0, 2, 1, 2, 1, 0, 0, 1, 4, 3, 3,\n",
      "        2, 4, 1, 3, 4, 1, 1, 0], device='cuda:0')\n",
      "tensor([3, 1, 1, 3, 0, 4, 1, 4, 3, 4, 1, 4, 4, 4, 1, 1, 4, 4, 4, 3, 4, 4, 3, 3,\n",
      "        4, 4, 3, 3, 4, 1, 0, 0], device='cuda:0')\n",
      "tensor(1.3939, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch  22. Approx. train error rate: 0.562. Val error rate: 0.719.\n",
      "Epoch 22/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[ 0.6993,  0.6671, -0.2451, -2.8972, -0.5102],\n",
      "        [ 0.5340,  1.8505,  0.3090, -3.6563, -1.2527],\n",
      "        [ 0.8493,  0.6380, -0.2248, -3.1338, -1.2173],\n",
      "        [-2.4622,  0.6817, -2.3245,  1.1465,  0.7756],\n",
      "        [ 1.1088,  1.4898,  0.1322, -2.0078, -0.6480],\n",
      "        [ 0.6720,  0.5560,  0.0783, -3.4922, -1.2132],\n",
      "        [-1.8498,  0.7464, -1.9143,  0.5063,  0.4774],\n",
      "        [-1.0000,  0.2731, -1.9612, -0.3708,  1.2043],\n",
      "        [-1.1679,  0.7706, -1.5055, -1.1622,  1.1353],\n",
      "        [ 1.9344,  1.1490,  0.3297, -3.0693, -1.3341],\n",
      "        [ 0.6952,  0.6424, -0.1201, -2.5949, -1.2377],\n",
      "        [ 1.3269,  1.9477,  0.4268, -3.9866, -1.2306],\n",
      "        [ 1.1106,  1.2029,  0.0093, -3.5126, -1.5807],\n",
      "        [-0.2543,  1.5209, -0.9114, -1.5318,  0.2010],\n",
      "        [ 1.8249,  1.2264,  1.1415, -3.6711, -1.6219],\n",
      "        [ 0.1980,  0.8127, -0.4334, -2.0971, -0.2730],\n",
      "        [ 0.8641,  0.9847, -0.3509, -2.7782, -0.9524],\n",
      "        [ 0.1038,  1.1583, -0.4349, -2.4131,  0.0128],\n",
      "        [ 1.4269,  1.1423,  0.5475, -3.1171, -1.2764],\n",
      "        [-1.5342,  0.1130, -1.7176,  2.4323,  1.1596],\n",
      "        [ 1.3101,  0.7562,  0.2938, -3.6403, -2.1785],\n",
      "        [ 2.0403,  1.5173,  0.8057, -4.7637, -2.0096],\n",
      "        [ 1.2288,  0.8131,  0.1880, -3.7706, -1.3555],\n",
      "        [-0.2558,  0.8970, -0.4298, -2.5010, -0.4566],\n",
      "        [ 0.6282,  0.7629, -0.4872, -2.7909, -1.3393],\n",
      "        [-2.4227,  0.8678, -2.2003,  0.2814,  0.6646],\n",
      "        [ 0.6002,  1.0571, -0.0177, -3.0575, -0.7442],\n",
      "        [ 1.3622,  0.7893, -0.0800, -3.2298, -0.8928],\n",
      "        [-0.1181,  0.4754, -0.9709, -1.3193, -0.0886],\n",
      "        [ 0.0184,  0.6601, -0.6572, -1.6266, -0.4543],\n",
      "        [ 0.4422,  1.0786,  0.4330, -2.6369, -1.1535],\n",
      "        [-2.0881,  0.4891, -1.4795,  2.0297,  0.7052]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([0, 1, 2, 3, 2, 0, 3, 4, 4, 0, 2, 2, 2, 4, 0, 1, 2, 4, 0, 3, 1, 1, 2, 2,\n",
      "        1, 3, 0, 1, 0, 0, 2, 3], device='cuda:0')\n",
      "tensor([0, 1, 0, 3, 1, 0, 1, 4, 4, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 3, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 3], device='cuda:0')\n",
      "tensor(1.2584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch  23. Approx. train error rate: 0.594. Val error rate: 0.688.\n",
      "Epoch 23/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[ 2.5757e+00,  1.1841e+00,  1.6398e+00, -4.9573e+00, -2.3330e+00],\n",
      "        [-1.5185e+00,  4.3311e-01, -1.4738e+00,  1.7107e+00,  4.1302e-01],\n",
      "        [ 1.5144e+00,  9.2737e-01,  6.4162e-01, -2.6105e+00, -1.8022e+00],\n",
      "        [-2.7313e-02,  5.0693e-01, -3.3566e-02, -1.0230e+00, -7.6961e-01],\n",
      "        [ 1.3102e+00,  1.6492e+00,  1.3468e+00, -4.2099e+00, -1.9183e+00],\n",
      "        [ 8.9890e-01,  8.1081e-01,  4.7860e-01, -3.3899e+00, -1.1786e+00],\n",
      "        [ 1.4192e+00,  1.2983e+00,  1.0273e+00, -4.6053e+00, -2.1662e+00],\n",
      "        [ 6.3170e-01,  1.0379e+00,  6.0301e-01, -3.4827e+00, -1.3110e+00],\n",
      "        [ 1.5507e+00,  1.4230e+00,  1.3158e+00, -4.7559e+00, -2.2883e+00],\n",
      "        [ 1.1285e+00,  1.1083e+00,  1.1331e+00, -3.2391e+00, -1.5690e+00],\n",
      "        [-1.7582e+00,  1.7293e-02, -1.4648e+00,  1.5567e+00, -1.8260e-01],\n",
      "        [-7.0948e-02,  1.5868e+00,  1.1221e-01, -1.9938e+00, -8.0053e-01],\n",
      "        [ 3.4191e-01,  1.2578e+00,  9.5282e-01, -3.5007e+00, -1.4931e+00],\n",
      "        [ 6.9541e-01,  1.3466e+00,  2.9198e-01, -2.1330e+00, -1.5385e+00],\n",
      "        [-2.8714e-01,  5.9636e-01,  3.6415e-01, -1.5842e+00, -1.1277e+00],\n",
      "        [ 2.1629e+00,  1.1409e+00,  1.2416e+00, -4.4123e+00, -2.1476e+00],\n",
      "        [ 1.1608e+00,  1.4548e+00,  6.4289e-01, -3.7889e+00, -1.2236e+00],\n",
      "        [ 6.1358e-01,  2.4923e-03,  2.8225e-01, -2.6063e+00, -1.0593e+00],\n",
      "        [ 1.2729e+00,  7.4265e-01,  6.6175e-01, -3.5396e+00, -1.9476e+00],\n",
      "        [-1.0922e+00,  7.9612e-02, -8.3603e-01,  1.4244e-01,  8.9237e-03],\n",
      "        [-2.3339e-01,  1.0895e+00, -4.6569e-01,  1.3137e-01,  3.3363e-01],\n",
      "        [ 8.5288e-01,  1.1267e+00,  8.0887e-01, -3.4281e+00, -1.5299e+00],\n",
      "        [ 4.7528e-01,  1.1879e+00, -1.9958e-01, -2.5487e+00, -8.1426e-01],\n",
      "        [-1.7230e-01,  1.7354e+00, -3.3532e-01, -2.3641e+00, -3.2189e-01],\n",
      "        [ 1.2026e+00,  1.1822e+00,  9.5046e-01, -2.9119e+00, -1.4501e+00],\n",
      "        [ 9.5457e-01,  7.1650e-01,  6.0686e-01, -3.3381e+00, -1.6315e+00],\n",
      "        [ 6.8190e-01,  1.0542e+00,  3.6604e-01, -1.7852e+00, -1.4765e+00],\n",
      "        [ 1.8045e-01,  1.5548e+00, -1.3992e-01, -2.7692e+00, -5.8760e-01],\n",
      "        [ 1.5004e+00,  1.2965e+00,  1.2049e+00, -3.9279e+00, -2.0517e+00],\n",
      "        [ 1.3443e+00,  9.3652e-01,  5.4168e-01, -3.1607e+00, -1.4920e+00],\n",
      "        [-1.2268e+00,  2.9040e-01, -5.2250e-01, -1.8138e-01,  3.8827e-01],\n",
      "        [ 1.0151e-01,  1.1635e+00,  3.6331e-03, -2.6105e+00, -8.4082e-01]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([0, 3, 2, 3, 2, 4, 0, 4, 1, 1, 3, 1, 4, 1, 3, 0, 0, 2, 0, 3, 1, 0, 2, 4,\n",
      "        1, 1, 3, 1, 1, 2, 3, 1], device='cuda:0')\n",
      "tensor([0, 3, 0, 1, 1, 0, 0, 1, 0, 2, 3, 1, 1, 1, 1, 0, 1, 0, 0, 3, 1, 1, 1, 1,\n",
      "        0, 0, 1, 1, 0, 0, 4, 1], device='cuda:0')\n",
      "tensor(1.4628, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch  24. Approx. train error rate: 0.625. Val error rate: 0.719.\n",
      "Epoch 24/24\n",
      "--------------------\n",
      "here final:  torch.Size([32, 5])\n",
      "tensor([[ 1.5385,  0.8747,  1.4957, -4.4724, -2.4425],\n",
      "        [ 1.0980,  1.4911,  1.4308, -3.9553, -2.2508],\n",
      "        [ 0.8831,  0.5323,  1.0237, -3.8460, -1.3872],\n",
      "        [-0.9064,  0.4599, -0.1497, -1.5300, -0.0517],\n",
      "        [-0.2913,  0.8418,  0.1687, -1.6890, -0.3393],\n",
      "        [-0.9249,  0.0378, -0.6484, -0.2547, -0.1594],\n",
      "        [ 1.1126,  0.6525,  0.9268, -3.0775, -1.5754],\n",
      "        [-0.3970,  0.1485, -0.5948, -0.1772, -0.4806],\n",
      "        [-0.6031,  0.7917,  0.2091, -1.7387, -0.2860],\n",
      "        [ 2.2735,  1.1057,  1.5640, -4.4169, -2.1367],\n",
      "        [-0.2962,  0.4425,  0.8693, -1.6450, -1.3688],\n",
      "        [-2.1399,  0.2627, -1.2067,  0.8766, -0.0774],\n",
      "        [ 1.1296,  0.8046,  0.9939, -3.8077, -2.3252],\n",
      "        [ 0.4172,  0.7578,  0.5060, -3.4856, -1.0868],\n",
      "        [ 1.4015,  0.7335,  1.5357, -4.2390, -1.7469],\n",
      "        [ 0.0596,  0.9775,  0.7373, -2.7949, -1.1644],\n",
      "        [ 0.3885,  1.5212,  1.3677, -3.6658, -1.6016],\n",
      "        [-1.0737,  0.8464,  0.5905, -1.4006, -0.7338],\n",
      "        [ 1.4973,  1.0863,  1.5027, -4.5708, -1.9354],\n",
      "        [ 0.2667, -0.0247, -0.2073, -2.5119, -1.0094],\n",
      "        [ 0.9053,  1.2255,  1.6653, -3.7761, -2.0005],\n",
      "        [ 0.4074,  0.8589,  0.9171, -3.1028, -1.6021],\n",
      "        [ 1.0152,  0.3561,  0.6050, -3.0102, -1.5301],\n",
      "        [-0.3716,  0.9387,  0.1062, -1.8554, -0.3265],\n",
      "        [ 1.3143,  0.7819,  0.8672, -2.6072, -1.5652],\n",
      "        [ 0.7896,  0.6601,  0.8632, -2.8088, -1.5243],\n",
      "        [ 0.8115,  0.8982,  1.0287, -3.4136, -1.6213],\n",
      "        [ 0.4156,  0.5876,  0.3404, -3.0886, -1.5354],\n",
      "        [-0.2261,  1.0594,  0.2626, -3.0981, -0.7361],\n",
      "        [ 0.6735,  0.2828,  0.0626, -2.2229, -1.0820],\n",
      "        [ 0.4604,  0.4183,  0.7663, -3.5498, -1.9975],\n",
      "        [ 1.2843,  1.0679,  1.3725, -4.0710, -2.4198]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "p_batch tensor([0, 1, 1, 4, 4, 3, 0, 3, 4, 0, 3, 3, 2, 4, 2, 0, 1, 4, 0, 4, 2, 4, 2, 4,\n",
      "        2, 0, 4, 2, 1, 0, 0, 2], device='cuda:0')\n",
      "tensor([0, 1, 2, 1, 1, 1, 0, 1, 1, 0, 2, 3, 0, 1, 2, 1, 1, 1, 2, 0, 2, 2, 0, 1,\n",
      "        0, 2, 2, 1, 1, 0, 2, 2], device='cuda:0')\n",
      "tensor(1.5249, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "here final:  torch.Size([32, 5])\n",
      "Epoch  25. Approx. train error rate: 0.656. Val error rate: 0.750.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 20)\n",
    "    train_loss, train_error = train_for_one_epoch()\n",
    "    val_loss, val_error = val()\n",
    "    \n",
    "    epoch += 1\n",
    "    epochs.append(epoch)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_errors.append(train_error)\n",
    "    val_losses.append(val_loss)\n",
    "    val_errors.append(val_error)\n",
    "    \n",
    "    print(f'Epoch {epoch:3d}. Approx. train error rate: {train_error:.3f}. Val error rate: {val_error:.3f}.')\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, sharex=True)\n",
    "ax[0].plot(train_losses, label='train loss')\n",
    "ax[0].plot(val_losses, label='val loss')\n",
    "ax[0].legend()\n",
    "ax[1].plot(train_errors, label='train error rate')\n",
    "ax[1].plot(val_errors, label='val error rate')\n",
    "ax[1].legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "Labels = Variable(labels.cuda())\n",
    "label_batch = Labels.float()\n",
    "grid = torchvision.utils.make_grid(images, nrow=8).cpu().numpy().transpose(1, 2, 0)\n",
    "grid = TRAIN_STD * grid + TRAIN_MEAN\n",
    "\n",
    "# The min and max values are very close to 0.0 and 1.0, but\n",
    "# are just outside because of numerical effects.\n",
    "grid = np.clip(grid, 0.0, 1.0)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(grid)\n",
    "label_batch = label_batch.cpu().numpy()\n",
    "label_batch = label_batch-1\n",
    "label_batch = Variable(torch.FloatTensor(label_batch).cuda())\n",
    "label_batch = label_batch.int()\n",
    "print(label_batch)\n",
    "print(' '.join('%5s' % classes[label_batch[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tm(images.cuda())\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print(predicted)\n",
    "\n",
    "print(\"Val error_rate: \", 1-(predicted.int() == label_batch).float().mean())\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        labels = labels.cpu().numpy()\n",
    "        labels = labels-1\n",
    "        labels = torch.FloatTensor(labels).cuda()\n",
    "        outputs = tm(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        print(labels)\n",
    "        print(predicted)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.long()).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(5))\n",
    "class_total = list(0. for i in range(5))\n",
    "\n",
    "import sys\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        \n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        labels = labels.cpu().numpy()\n",
    "        labels = labels-1\n",
    "        labels = torch.FloatTensor(labels).cuda()\n",
    "        \n",
    "        outputs = tm(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels.long()).squeeze()\n",
    "        if len(labels) > 0:\n",
    "            for i in range(len(c)):\n",
    "                label = labels[i]\n",
    "                print(c)\n",
    "                class_correct[label.int().item()] += c[i].int().item()\n",
    "                class_total[label.int().item()] += 1\n",
    "        elif len(c) == 0:\n",
    "            label = labels[0]\n",
    "            class_correct[label.int().item()] += c.item()\n",
    "            class_total[label.int().item()] += 1\n",
    "            \n",
    "print(class_correct)\n",
    "print(class_total)\n",
    "\n",
    "for i in range(5):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
